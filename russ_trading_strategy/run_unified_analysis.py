#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€èµ„äº§åˆ†ææ‰§è¡Œè„šæœ¬
Unified Asset Analysis Runner

ä¸€æ¬¡è¿è¡Œåˆ†ææ‰€æœ‰æ ‡çš„(æŒ‡æ•°ã€æ¿å—ã€ä¸ªè‚¡)
æ•´åˆäº† comprehensive_asset_analysis å’Œ sector_analysis çš„åŠŸèƒ½

è¿è¡Œæ–¹å¼:
  python scripts/unified_analysis/run_unified_analysis.py
  python scripts/unified_analysis/run_unified_analysis.py --assets CYBZ HK_BIOTECH SANHUA_A
  python scripts/unified_analysis/run_unified_analysis.py --save reports/unified_report.md
  python scripts/unified_analysis/run_unified_analysis.py --format markdown
  python scripts/unified_analysis/run_unified_analysis.py --list

ä½œè€…: Claude Code
æ—¥æœŸ: 2025-10-16
"""

import sys
import argparse
import logging
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from russ_trading_strategy.unified_config import (
    UNIFIED_ASSETS,
    list_all_assets,
    list_assets_by_analyzer,
    get_asset_config
)
from scripts.comprehensive_asset_analysis.asset_reporter import ComprehensiveAssetReporter
from scripts.sector_analysis.sector_reporter import SectorReporter
from russ_trading_strategy.unified_email_notifier import UnifiedEmailNotifier

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class UnifiedAnalysisRunner:
    """ç»Ÿä¸€èµ„äº§åˆ†ææ‰§è¡Œå™¨"""

    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.comprehensive_reporter = None
        self.sector_reporter = None

    def analyze_assets(self, asset_keys: list = None) -> dict:
        """
        åˆ†æèµ„äº§

        Args:
            asset_keys: èµ„äº§ä»£ç åˆ—è¡¨,Noneè¡¨ç¤ºåˆ†ææ‰€æœ‰èµ„äº§

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        if asset_keys is None:
            asset_keys = list(UNIFIED_ASSETS.keys())

        logger.info(f"å‡†å¤‡åˆ†æ {len(asset_keys)} ä¸ªèµ„äº§...")

        results = {
            'timestamp': datetime.now(),
            'date': datetime.now().strftime('%Y-%m-%d'),
            'assets': {}
        }

        # æŒ‰åˆ†æå™¨ç±»å‹åˆ†ç»„
        comprehensive_assets = []
        sector_assets = []

        for asset_key in asset_keys:
            if asset_key not in UNIFIED_ASSETS:
                logger.warning(f"èµ„äº§ {asset_key} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                continue

            config = UNIFIED_ASSETS[asset_key]
            if config['analyzer_type'] == 'comprehensive':
                comprehensive_assets.append(asset_key)
            elif config['analyzer_type'] == 'sector':
                sector_assets.append(asset_key)

        # åˆ†ææŒ‡æ•°ç±»èµ„äº§ (ä½¿ç”¨ ComprehensiveAssetReporter)
        if comprehensive_assets:
            logger.info(f"åˆ†ææŒ‡æ•°ç±»èµ„äº§: {', '.join(comprehensive_assets)}")
            if self.comprehensive_reporter is None:
                self.comprehensive_reporter = ComprehensiveAssetReporter()

            for asset_key in comprehensive_assets:
                try:
                    logger.info(f"åˆ†æ {UNIFIED_ASSETS[asset_key]['name']}...")
                    result = self.comprehensive_reporter.analyze_single_asset(asset_key)
                    results['assets'][asset_key] = result
                except Exception as e:
                    logger.error(f"åˆ†æ {asset_key} å¤±è´¥: {str(e)}")
                    results['assets'][asset_key] = {
                        'error': str(e),
                        'asset_name': UNIFIED_ASSETS[asset_key]['name']
                    }

        # åˆ†ææ¿å—ç±»èµ„äº§ (ä½¿ç”¨ SectorReporter)
        if sector_assets:
            logger.info(f"åˆ†ææ¿å—ç±»èµ„äº§: {', '.join(sector_assets)}")
            if self.sector_reporter is None:
                self.sector_reporter = SectorReporter()

            for asset_key in sector_assets:
                try:
                    logger.info(f"åˆ†æ {UNIFIED_ASSETS[asset_key]['name']}...")
                    result = self.sector_reporter.analyze_single_sector(asset_key)
                    results['assets'][asset_key] = result
                except Exception as e:
                    logger.error(f"åˆ†æ {asset_key} å¤±è´¥: {str(e)}")
                    results['assets'][asset_key] = {
                        'error': str(e),
                        'asset_name': UNIFIED_ASSETS[asset_key]['name']
                    }

        logger.info("æ‰€æœ‰èµ„äº§åˆ†æå®Œæˆ")
        return results

    def format_report(self, results: dict, format_type: str = 'markdown') -> str:
        """
        æ ¼å¼åŒ–æŠ¥å‘Š

        ç›´æ¥è°ƒç”¨åŸæœ‰æŠ¥å‘Šç”Ÿæˆå™¨çš„æ–¹æ³•,ç¡®ä¿æ•°æ®å®Œæ•´å±•ç¤º

        Args:
            results: åˆ†æç»“æœ
            format_type: æŠ¥å‘Šæ ¼å¼ ('text' æˆ– 'markdown')

        Returns:
            æ ¼å¼åŒ–åçš„æŠ¥å‘Šæ–‡æœ¬
        """
        lines = []

        # æŠ¥å‘Šå¤´éƒ¨
        if format_type == 'markdown':
            lines.append("# ğŸ“Š ç»Ÿä¸€èµ„äº§åˆ†ææŠ¥å‘Š")
            lines.append("")
            lines.append(f"**ç”Ÿæˆæ—¶é—´**: {results['date']}")
            lines.append("")
            lines.append("---")
            lines.append("")
        else:
            lines.append("=" * 80)
            lines.append("ç»Ÿä¸€èµ„äº§åˆ†ææŠ¥å‘Š".center(80))
            lines.append(f"ç”Ÿæˆæ—¶é—´: {results['date']}".center(80))
            lines.append("=" * 80)
            lines.append("")

        # ç»Ÿè®¡ä¿¡æ¯
        total_count = len(results['assets'])
        success_count = sum(1 for data in results['assets'].values() if 'error' not in data)
        fail_count = total_count - success_count

        if format_type == 'markdown':
            lines.append("## ğŸ“‹ åˆ†ææ¦‚è§ˆ")
            lines.append("")
            lines.append(f"- **æ€»èµ„äº§æ•°**: {total_count}")
            lines.append(f"- **æˆåŠŸåˆ†æ**: {success_count}")
            lines.append(f"- **å¤±è´¥æ•°**: {fail_count}")
            lines.append("")
        else:
            lines.append(f"æ€»èµ„äº§æ•°: {total_count}")
            lines.append(f"æˆåŠŸåˆ†æ: {success_count}")
            lines.append(f"å¤±è´¥æ•°: {fail_count}")
            lines.append("")
            lines.append("=" * 80)
            lines.append("")

        # ç”Ÿæˆæ±‡æ€»è¡¨æ ¼
        if format_type == 'markdown':
            summary_table = self._generate_summary_table(results)
            if summary_table:
                lines.append("## ğŸ“Š æ ‡çš„æ±‡æ€»")
                lines.append("")
                lines.append(summary_table)
                lines.append("")
            lines.append("---")
            lines.append("")

        # åˆ†ç»„æ•´ç†æŠ¥å‘Šæ•°æ®
        comprehensive_report = {'assets': {}}
        sector_reports = []

        for asset_key, data in results['assets'].items():
            if 'error' in data:
                continue

            config = UNIFIED_ASSETS[asset_key]
            if config['analyzer_type'] == 'comprehensive':
                comprehensive_report['assets'][asset_key] = data
            elif config['analyzer_type'] == 'sector':
                sector_reports.append((asset_key, data, config))

        # ç”ŸæˆæŒ‡æ•°ç±»èµ„äº§æŠ¥å‘Š (ä½¿ç”¨ ComprehensiveAssetReporter)
        if comprehensive_report['assets'] and self.comprehensive_reporter:
            comprehensive_report['timestamp'] = results['timestamp']
            comprehensive_report['date'] = results['date']

            if format_type == 'markdown':
                lines.append(self.comprehensive_reporter.format_markdown_report(comprehensive_report))
            else:
                lines.append(self.comprehensive_reporter.format_text_report(comprehensive_report))

        # ç”Ÿæˆæ¿å—ç±»èµ„äº§æŠ¥å‘Š (ä½¿ç”¨ SectorReporter)
        if sector_reports and self.sector_reporter:
            for asset_key, data, config in sector_reports:
                # æ„é€ å•ä¸ªæ¿å—çš„æŠ¥å‘Šæ•°æ®
                single_sector_report = {
                    'timestamp': results['timestamp'],
                    'date': results['date'],
                    'sectors': {asset_key: data}
                }

                if format_type == 'markdown':
                    # SectorReporter åªæœ‰ format_text_report,æˆ‘ä»¬éœ€è¦æ‰‹åŠ¨ç”Ÿæˆ markdown
                    lines.append(self._format_sector_markdown(asset_key, data, config))
                else:
                    lines.append(self.sector_reporter.format_text_report(single_sector_report))

        # å¤±è´¥çš„èµ„äº§
        if fail_count > 0:
            if format_type == 'markdown':
                lines.append("## âš ï¸ åˆ†æå¤±è´¥")
                lines.append("")
                for asset_key, data in results['assets'].items():
                    if 'error' in data:
                        lines.append(f"- **{data.get('asset_name', asset_key)}**: {data['error']}")
                lines.append("")
            else:
                lines.append("-" * 80)
                lines.append("åˆ†æå¤±è´¥")
                lines.append("-" * 80)
                for asset_key, data in results['assets'].items():
                    if 'error' in data:
                        lines.append(f"{data.get('asset_name', asset_key)}: {data['error']}")
                lines.append("")

        # æŠ¥å‘Šå°¾éƒ¨
        if format_type == 'markdown':
            lines.append("---")
            lines.append("")
            lines.append("**å…è´£å£°æ˜**: æœ¬æŠ¥å‘Šä»…ä¾›å‚è€ƒ,ä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚æŠ•èµ„æœ‰é£é™©,å…¥å¸‚éœ€è°¨æ…ã€‚")
            lines.append("")
            lines.append(f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {results['date']}*")
        else:
            lines.append("=" * 80)
            lines.append("å…è´£å£°æ˜: æœ¬æŠ¥å‘Šä»…ä¾›å‚è€ƒ,ä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚æŠ•èµ„æœ‰é£é™©,å…¥å¸‚éœ€è°¨æ…ã€‚")
            lines.append("=" * 80)

        return '\n'.join(lines)

    def _generate_summary_table(self, results: dict) -> str:
        """ç”Ÿæˆæ‰€æœ‰æ ‡çš„æ±‡æ€»è¡¨æ ¼"""
        lines = []

        # è¡¨å¤´ (æ·»åŠ æŒæœ‰å»ºè®®åˆ—)
        lines.append("| æ ‡çš„åç§° | å½“å‰ä»·æ ¼ | æ¶¨è·Œå¹… | æ–¹å‘åˆ¤æ–­ | å»ºè®®ä»“ä½ | 20æ—¥ä¸Šæ¶¨æ¦‚ç‡ | é£é™©ç­‰çº§ | æŒæœ‰å»ºè®® |")
        lines.append("|----------|----------|--------|----------|----------|--------------|----------|----------|")

        # éå†æ‰€æœ‰èµ„äº§
        for asset_key, data in results['assets'].items():
            if 'error' in data:
                continue

            config = UNIFIED_ASSETS[asset_key]

            # æ ‡çš„åç§°
            if config['analyzer_type'] == 'comprehensive':
                asset_name = data.get('asset_name', config['name'])
            else:
                asset_name = data.get('sector_name', config['name'])

            # å½“å‰ä»·æ ¼å’Œæ¶¨è·Œå¹… - ä¿®å¤å­—æ®µåç§°
            # comprehensive ç±»å‹ä½¿ç”¨ 'historical_analysis', sector ç±»å‹ä¹Ÿä½¿ç”¨ 'historical_analysis'
            hist = data.get('historical_analysis', {})

            current_price = hist.get('current_price', 0)
            change_pct = hist.get('current_change_pct', 0)
            # ä¸­å›½è‚¡å¸‚ä¹ æƒ¯: çº¢æ¶¨ç»¿è·Œ
            change_emoji = "ğŸ”´" if change_pct >= 0 else "ğŸŸ¢"

            # ç»¼åˆåˆ¤æ–­
            judgment = data.get('comprehensive_judgment', {})
            direction = judgment.get('direction', 'N/A')
            position = judgment.get('recommended_position', 'N/A')

            # æ–¹å‘åˆ¤æ–­emoji
            direction_map = {
                'å¼ºçƒˆçœ‹å¤š': 'âœ…âœ…',
                'çœ‹å¤š': 'âœ…',
                'ä¸­æ€§åå¤š': 'âš–ï¸',
                'ä¸­æ€§': 'âš–ï¸',
                'çœ‹ç©º': 'ğŸ”´'
            }
            direction_with_emoji = f"{direction}{direction_map.get(direction, '')}"

            # 20æ—¥ä¸Šæ¶¨æ¦‚ç‡ (comprehensive å’Œ sector ä½¿ç”¨ç›¸åŒå­—æ®µ)
            stats_20d = hist.get('20d', {})
            up_prob_20d = stats_20d.get('up_prob', 0)
            # ç»™ä¸Šæ¶¨æ¦‚ç‡æ·»åŠ é¢œè‰²: >=60%çº¢è‰²(çœ‹æ¶¨), <40%ç»¿è‰²(çœ‹è·Œ), 40-60%æ— è‰²
            if up_prob_20d >= 0.6:
                prob_emoji = "ğŸ”´"
            elif up_prob_20d < 0.4:
                prob_emoji = "ğŸŸ¢"
            else:
                prob_emoji = ""
            prob_display = f"{up_prob_20d:.1%} {prob_emoji}" if prob_emoji else f"{up_prob_20d:.1%}"

            # é£é™©ç­‰çº§
            risk = data.get('risk_assessment', {})
            risk_level = risk.get('risk_level', 'N/A')
            risk_emoji_map = {
                'æé«˜é£é™©': 'ğŸ”´ğŸ”´ğŸ”´',
                'é«˜é£é™©': 'ğŸ”´ğŸ”´',
                'ä¸­é£é™©': 'âš ï¸',
                'ä½é£é™©': 'âœ…'
            }
            risk_with_emoji = f"{risk_emoji_map.get(risk_level, '')} {risk_level}"

            # æŒæœ‰å»ºè®® - ä» strategies ä¸­æå–åŒ…å«"æŒæœ‰"çš„å»ºè®®
            strategies = judgment.get('strategies', [])
            hold_suggestion = '-'
            for strategy in strategies:
                # åŒ¹é…åŒ…å«"æŒæœ‰"å…³é”®è¯çš„å»ºè®®
                if 'æŒæœ‰' in strategy:
                    hold_suggestion = strategy
                    break

            # ç”Ÿæˆè¡¨æ ¼è¡Œ (æ·»åŠ æŒæœ‰å»ºè®®åˆ—)
            lines.append(
                f"| {asset_name} | {current_price:.2f} | "
                f"{change_pct:+.2f}% {change_emoji} | {direction_with_emoji} | {position} | "
                f"{prob_display} | {risk_with_emoji} | {hold_suggestion} |"
            )

        return '\n'.join(lines)

    def _format_sector_markdown(self, asset_key: str, data: dict, config: dict) -> str:
        """æ ¼å¼åŒ–å•ä¸ªæ¿å—ä¸º Markdown (å‚è€ƒ SectorReporter çš„æ ¼å¼)"""
        lines = []

        # æ ‡é¢˜
        lines.append(f"## {config['category'].upper()}: {data.get('sector_name', config['name'])}")
        lines.append("")
        lines.append(f"**æè¿°**: {config.get('description', 'N/A')}")
        lines.append("")

        # 1. å½“å‰ç‚¹ä½
        hist = data.get('historical_analysis', {})
        if hist and 'current_price' in hist:
            lines.append("### å½“å‰ç‚¹ä½")
            lines.append(f"- **æœ€æ–°ä»·æ ¼**: {hist['current_price']:.2f}")

            change_pct = hist.get('current_change_pct', 0)
            # ä¸­å›½è‚¡å¸‚ä¹ æƒ¯: çº¢æ¶¨ç»¿è·Œ
            change_emoji = "ğŸ”´" if change_pct >= 0 else "ğŸŸ¢"
            lines.append(f"- **æ¶¨è·Œå¹…**: {change_pct:+.2f}% {change_emoji}")
            lines.append(f"- **æ•°æ®æ—¥æœŸ**: {hist.get('current_date', 'N/A')}")
            lines.append("")

        # 2. ç»¼åˆåˆ¤æ–­
        judgment = data.get('comprehensive_judgment', {})
        if judgment:
            lines.append("### ç»¼åˆåˆ¤æ–­")

            direction = judgment.get('direction', 'N/A')
            direction_emoji_map = {
                'å¼ºçƒˆçœ‹å¤š': 'âœ…âœ…',
                'çœ‹å¤š': 'âœ…',
                'ä¸­æ€§åå¤š': 'âš–ï¸',
                'ä¸­æ€§': 'âš–ï¸',
                'çœ‹ç©º': 'ğŸ”´'
            }
            direction_emoji = direction_emoji_map.get(direction, 'âš–ï¸')
            lines.append(f"- **æ–¹å‘åˆ¤æ–­**: {direction}{direction_emoji}")
            lines.append(f"- **å»ºè®®ä»“ä½**: {judgment.get('recommended_position', 'N/A')}")
            lines.append("")

            strategies = judgment.get('strategies', [])
            if strategies:
                lines.append("**æ“ä½œç­–ç•¥**:")
                for strategy in strategies:
                    lines.append(f"  - {strategy}")
                lines.append("")

        # 3. å†å²ç‚¹ä½åˆ†æ
        if hist and '20d' in hist:
            lines.append("### å†å²ç‚¹ä½åˆ†æ")
            lines.append(f"- **ç›¸ä¼¼ç‚¹ä½**: {hist.get('similar_periods_count', 0)} ä¸ª")
            lines.append("")
            lines.append("| å‘¨æœŸ | ä¸Šæ¶¨æ¦‚ç‡ | å¹³å‡æ”¶ç›Š | æ”¶ç›Šä¸­ä½ | ç½®ä¿¡åº¦ |")
            lines.append("|------|----------|----------|----------|--------|")

            stats_20d = hist.get('20d', {})
            if stats_20d:
                lines.append(
                    f"| æœªæ¥20æ—¥ | {stats_20d.get('up_prob', 0):.1%} | "
                    f"{stats_20d.get('mean_return', 0):+.2%} | "
                    f"{stats_20d.get('median_return', 0):+.2%} | "
                    f"{stats_20d.get('confidence', 0):.1%} |"
                )

            stats_60d = hist.get('60d', {})
            if stats_60d and stats_60d.get('confidence', 0) > 0:
                lines.append(
                    f"| æœªæ¥60æ—¥ | {stats_60d.get('up_prob', 0):.1%} | "
                    f"{stats_60d.get('mean_return', 0):+.2%} | - | - |"
                )

            lines.append("")

        # 4. æŠ€æœ¯é¢åˆ†æ
        tech = data.get('technical_analysis', {})
        if tech and 'error' not in tech:
            lines.append("### æŠ€æœ¯é¢åˆ†æ")

            # MACD
            if 'macd' in tech:
                macd_status = 'âœ… é‡‘å‰' if tech['macd']['status'] == 'golden_cross' else 'ğŸ”´ æ­»å‰'
                lines.append(f"- **MACD**: {macd_status}")

            # RSI
            if 'rsi' in tech:
                rsi_val = tech['rsi']['value']
                rsi_status_map = {
                    'overbought': 'âš ï¸ è¶…ä¹°',
                    'oversold': 'âœ… è¶…å–',
                    'normal': 'ğŸ˜Š æ­£å¸¸'
                }
                rsi_status = rsi_status_map.get(tech['rsi']['status'], '')
                lines.append(f"- **RSI**: {rsi_val:.1f} ({rsi_status})")

            # KDJ
            if 'kdj' in tech:
                kdj = tech['kdj']
                kdj_signal = 'âœ…' if kdj['signal'] == 'golden_cross' else 'ğŸ”´'
                lines.append(f"- **KDJ**: K={kdj['k']:.1f}, D={kdj['d']:.1f}, J={kdj['j']:.1f} {kdj_signal}")

            # å¸ƒæ—å¸¦
            if 'boll' in tech:
                boll = tech['boll']
                boll_pos_pct = boll['position'] * 100
                boll_status_map = {
                    'near_upper': 'âš ï¸ æ¥è¿‘ä¸Šè½¨',
                    'near_lower': 'âœ… æ¥è¿‘ä¸‹è½¨',
                    'normal': 'ğŸ˜Š ä¸­è½¨åŒºåŸŸ'
                }
                boll_status = boll_status_map.get(boll['status'], '')
                lines.append(f"- **å¸ƒæ—å¸¦**: {boll_pos_pct:.0f}% ({boll_status})")

            # DMI/ADX
            if 'dmi_adx' in tech:
                dmi = tech['dmi_adx']
                trend_map = {'strong': 'strong ğŸ”¥', 'medium': 'medium ğŸ“Š', 'weak': 'weak âš¡'}
                direction_emoji = 'ğŸ“ˆ' if dmi['direction'] == 'bullish' else 'ğŸ“‰'
                lines.append(
                    f"- **DMI/ADX**: {dmi['adx']:.1f} ({trend_map.get(dmi['trend'], '')}, {direction_emoji})"
                )

            lines.append("")

        # 5. èµ„é‡‘é¢åˆ†æ
        capital = data.get('capital_flow', {})
        if capital and 'error' not in capital and capital.get('type'):
            lines.append("### èµ„é‡‘é¢åˆ†æ")
            flow_type = '**åŒ—å‘èµ„é‡‘(å¤–èµ„)**' if capital['type'] == 'northbound' else '**å—å‘èµ„é‡‘(å†…åœ°)**'
            lines.append(f"{flow_type}:")
            lines.append(f"- **è¿‘5æ—¥ç´¯è®¡**: {capital.get('recent_5d_flow', 0):.2f} äº¿å…ƒ")
            lines.append(f"- **æµå‘çŠ¶æ€**: {capital.get('status', 'N/A')}")
            lines.append(f"- **æƒ…ç»ªè¯„åˆ†**: {capital.get('sentiment_score', 50)}/100")
            lines.append("")

        # 6. é£é™©è¯„ä¼°
        risk = data.get('risk_assessment', {})
        if risk:
            lines.append("### é£é™©è¯„ä¼°")
            risk_level = risk.get('risk_level', 'N/A')
            risk_emoji_map = {
                'æé«˜é£é™©': 'ğŸ”´ğŸ”´ğŸ”´',
                'é«˜é£é™©': 'ğŸ”´ğŸ”´',
                'ä¸­é£é™©': 'âš ï¸',
                'ä½é£é™©': 'âœ…'
            }
            risk_emoji = risk_emoji_map.get(risk_level, '')
            lines.append(f"- **ç»¼åˆé£é™©**: {risk.get('risk_score', 0):.2f} ({risk_emoji} {risk_level})")

            risk_factors = risk.get('risk_factors', [])
            if risk_factors:
                lines.append("- **é£é™©å› ç´ **:")
                for factor in risk_factors:
                    lines.append(f"  - {factor}")

            lines.append("")

        # 7. æˆäº¤é‡åˆ†æ
        volume = data.get('volume_analysis', {})
        if volume and 'error' not in volume:
            lines.append("### æˆäº¤é‡åˆ†æ")
            obv = volume.get('obv_analysis', {})
            if obv:
                obv_trend = obv.get('trend', 'N/A')
                obv_emoji = 'â¡ï¸' if obv_trend in ['ä¸Šå‡', 'ä¸‹é™', 'å¹³ç¨³'] else ''
                lines.append(f"- **OBVè¶‹åŠ¿**: {obv_trend} {obv_emoji}")
            lines.append("")

        # 8. æ”¯æ’‘å‹åŠ›ä½
        sr = data.get('support_resistance', {})
        if sr and 'error' not in sr and sr.get('available', True):
            lines.append("### æ”¯æ’‘å‹åŠ›ä½")
            pivot = sr.get('pivot_points', {})
            if pivot:
                lines.append(f"- **è½´å¿ƒç‚¹**: {pivot.get('pivot', 0):.2f}")
                lines.append(f"- **é˜»åŠ›ä½**: R1={pivot.get('r1', 0):.2f}, R2={pivot.get('r2', 0):.2f}")
                lines.append(f"- **æ”¯æ’‘ä½**: S1={pivot.get('s1', 0):.2f}, S2={pivot.get('s2', 0):.2f}")
            lines.append("")

        lines.append("---")
        lines.append("")

        return '\n'.join(lines)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='ç»Ÿä¸€èµ„äº§åˆ†æå·¥å…· (æ•´åˆæŒ‡æ•°ã€æ¿å—ã€ä¸ªè‚¡åˆ†æ)'
    )
    parser.add_argument(
        '--assets',
        nargs='+',
        help='æŒ‡å®šèµ„äº§ä»£ç (å¦‚ CYBZ HK_BIOTECH SANHUA_A)ï¼Œä¸æŒ‡å®šåˆ™åˆ†ææ‰€æœ‰èµ„äº§'
    )
    parser.add_argument(
        '--save',
        type=str,
        help='ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶'
    )
    parser.add_argument(
        '--format',
        type=str,
        choices=['text', 'markdown'],
        default='markdown',
        help='æŠ¥å‘Šæ ¼å¼ (text æˆ– markdown)'
    )
    parser.add_argument(
        '--list',
        action='store_true',
        help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨èµ„äº§'
    )
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—'
    )
    parser.add_argument(
        '--email',
        action='store_true',
        help='å‘é€é‚®ä»¶åˆ°é…ç½®çš„æ”¶ä»¶äººåˆ—è¡¨'
    )

    args = parser.parse_args()

    # é…ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # åˆ—å‡ºæ‰€æœ‰èµ„äº§
    if args.list:
        print("=" * 80)
        print("æ‰€æœ‰å¯ç”¨èµ„äº§:")
        print("=" * 80)
        print(f"{'ä»£ç ':<20} {'åç§°':<20} {'ç±»åˆ«':<15} {'åˆ†æå™¨':<15}")
        print("-" * 80)

        for key, name, category, analyzer_type in list_all_assets():
            print(f"{key:<20} {name:<20} {category:<15} {analyzer_type:<15}")

        print("=" * 80)
        print(f"æ€»è®¡: {len(UNIFIED_ASSETS)} ä¸ªèµ„äº§")
        print("=" * 80)
        return

    try:
        print("=" * 80)
        print("ç»Ÿä¸€èµ„äº§åˆ†æå·¥å…·")
        print("=" * 80)

        # ç¡®å®šè¦åˆ†æçš„èµ„äº§
        asset_keys = args.assets
        if asset_keys:
            print(f"åˆ†æèµ„äº§: {', '.join(asset_keys)}")
        else:
            all_assets = list(UNIFIED_ASSETS.keys())
            asset_keys = all_assets
            print(f"åˆ†ææ‰€æœ‰èµ„äº§ ({len(asset_keys)} ä¸ª)")

        print("=" * 80)

        # æ‰§è¡Œåˆ†æ
        runner = UnifiedAnalysisRunner()
        results = runner.analyze_assets(asset_keys)

        # æ ¼å¼åŒ–æŠ¥å‘Š
        report = runner.format_report(results, args.format)

        # æ‰“å°åˆ°æ§åˆ¶å° (å¤„ç† Windows GBK ç¼–ç )
        try:
            print("\n" + report)
        except UnicodeEncodeError:
            # Windows æ§åˆ¶å° GBK ç¼–ç ä¸æ”¯æŒ emoji å’Œç‰¹æ®Šå­—ç¬¦
            text_safe = report.encode('gbk', errors='ignore').decode('gbk')
            print("\n" + text_safe)

        # ä¿å­˜åˆ°æ–‡ä»¶
        if args.save:
            save_path = Path(args.save)
            save_path.parent.mkdir(parents=True, exist_ok=True)
            with open(save_path, 'w', encoding='utf-8') as f:
                f.write(report)
            logger.info(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {save_path}")

        # å‘é€é‚®ä»¶(å§‹ç»ˆä½¿ç”¨æ–‡æœ¬æ ¼å¼)
        if args.email:
            logger.info("å‡†å¤‡å‘é€é‚®ä»¶åˆ°é…ç½®çš„æ”¶ä»¶äººåˆ—è¡¨...")
            try:
                # é‚®ä»¶å‘é€ä½¿ç”¨æ–‡æœ¬æ ¼å¼æŠ¥å‘Š
                text_report = runner.format_report(results, 'text')
                notifier = UnifiedEmailNotifier()
                success = notifier.send_unified_report(results, text_report)
                if success:
                    logger.info("âœ… é‚®ä»¶å‘é€æˆåŠŸ")
                else:
                    logger.error("âŒ é‚®ä»¶å‘é€å¤±è´¥")
                    sys.exit(1)
            except Exception as e:
                logger.error(f"é‚®ä»¶å‘é€å¼‚å¸¸: {str(e)}")
                logger.info("ğŸ’¡ æç¤º: è¯·ç¡®ä¿å·²é…ç½® config/email_config.yaml")
                sys.exit(1)

        logger.info("âœ… åˆ†æä»»åŠ¡å®Œæˆ")

    except Exception as e:
        logger.error(f"æ‰§è¡Œå¤±è´¥: {str(e)}", exc_info=True)
        sys.exit(1)


if __name__ == '__main__':
    main()
