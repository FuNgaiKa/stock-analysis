#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€èµ„äº§åˆ†ææ‰§è¡Œè„šæœ¬
Unified Asset Analysis Runner

ä¸€æ¬¡è¿è¡Œåˆ†ææ‰€æœ‰æ ‡çš„(æŒ‡æ•°ã€æ¿å—ã€ä¸ªè‚¡)
æ•´åˆäº† comprehensive_asset_analysis å’Œ sector_analysis çš„åŠŸèƒ½

è¿è¡Œæ–¹å¼:
  python scripts/unified_analysis/run_unified_analysis.py
  python scripts/unified_analysis/run_unified_analysis.py --assets CYBZ HK_BIOTECH SANHUA_A
  python scripts/unified_analysis/run_unified_analysis.py --save reports/unified_report.md
  python scripts/unified_analysis/run_unified_analysis.py --format markdown
  python scripts/unified_analysis/run_unified_analysis.py --list

ä½œè€…: Claude Code
æ—¥æœŸ: 2025-10-16
"""

import sys
import argparse
import logging
import json
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from russ_trading.config.unified_config import (
    UNIFIED_ASSETS,
    list_all_assets,
    list_assets_by_analyzer,
    get_asset_config
)
from scripts.analysis.comprehensive_asset_analysis.asset_reporter import ComprehensiveAssetReporter
from scripts.analysis.sector_analysis.sector_reporter import SectorReporter
from russ_trading.notifiers.unified_email_notifier import UnifiedEmailNotifier
from russ_trading.core.investment_advisor import InvestmentAdvisor
from russ_trading.generators.daily_position_report_generator import DailyPositionReportGenerator

# å¯¼å…¥æœºæ„çº§æ ¸å¿ƒæŒ‡æ ‡åˆ†æå™¨ (Phase 3.3)
try:
    from strategies.position.analyzers.valuation.index_valuation_analyzer import IndexValuationAnalyzer
    from strategies.position.analyzers.market_structure.market_breadth_analyzer import MarketBreadthAnalyzer
    from strategies.position.analyzers.market_specific.margin_trading_analyzer import MarginTradingAnalyzer
    HAS_CORE_ANALYZERS = True
except ImportError:
    HAS_CORE_ANALYZERS = False
    logging.warning("æœºæ„çº§æ ¸å¿ƒåˆ†æå™¨æœªæ‰¾åˆ°ï¼ˆä¼°å€¼/å®½åº¦/èèµ„ï¼‰")

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class UnifiedAnalysisRunner:
    """ç»Ÿä¸€èµ„äº§åˆ†ææ‰§è¡Œå™¨(ä¼˜åŒ–ç‰ˆ:æ”¯æŒå¹¶å‘+ç¼“å­˜)"""

    def __init__(self, max_workers: int = 6, enable_parallel: bool = True):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        Args:
            max_workers: æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°(é»˜è®¤6)
            enable_parallel: æ˜¯å¦å¯ç”¨å¹¶å‘æ‰§è¡Œ(é»˜è®¤True)
        """
        self.comprehensive_reporter = None
        self.sector_reporter = None
        self.investment_advisor = InvestmentAdvisor()
        self.max_workers = max_workers
        self.enable_parallel = enable_parallel

        # åˆå§‹åŒ–æœºæ„çº§æ ¸å¿ƒåˆ†æå™¨ (Phase 3.3)
        if HAS_CORE_ANALYZERS:
            self.valuation_analyzer = IndexValuationAnalyzer(lookback_days=2520)  # 10å¹´ä¼°å€¼å†å²
            self.breadth_analyzer = MarketBreadthAnalyzer(lookback_days=60)  # 60æ—¥å¸‚åœºå®½åº¦
            self.margin_analyzer = MarginTradingAnalyzer(lookback_days=252)  # 1å¹´èèµ„æ•°æ®
            logger.info("æœºæ„çº§æ ¸å¿ƒåˆ†æå™¨åˆå§‹åŒ–å®Œæˆï¼ˆä¼°å€¼/å®½åº¦/èèµ„ï¼‰")
        else:
            self.valuation_analyzer = None
            self.breadth_analyzer = None
            self.margin_analyzer = None

        logger.info(f"åˆ†æå™¨é…ç½®: å¹¶å‘={'å¯ç”¨' if enable_parallel else 'ç¦ç”¨'}, æœ€å¤§çº¿ç¨‹æ•°={max_workers}")

    def analyze_assets(self, asset_keys: list = None) -> dict:
        """
        åˆ†æèµ„äº§

        Args:
            asset_keys: èµ„äº§ä»£ç åˆ—è¡¨,Noneè¡¨ç¤ºåˆ†ææ‰€æœ‰èµ„äº§

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        if asset_keys is None:
            asset_keys = list(UNIFIED_ASSETS.keys())

        logger.info(f"å‡†å¤‡åˆ†æ {len(asset_keys)} ä¸ªèµ„äº§...")

        results = {
            'timestamp': datetime.now(),
            'date': datetime.now().strftime('%Y-%m-%d'),
            'assets': {}
        }

        # æŒ‰åˆ†æå™¨ç±»å‹åˆ†ç»„
        comprehensive_assets = []
        sector_assets = []

        for asset_key in asset_keys:
            if asset_key not in UNIFIED_ASSETS:
                logger.warning(f"èµ„äº§ {asset_key} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                continue

            config = UNIFIED_ASSETS[asset_key]
            if config['analyzer_type'] == 'comprehensive':
                comprehensive_assets.append(asset_key)
            elif config['analyzer_type'] == 'sector':
                sector_assets.append(asset_key)

        # åˆ†ææŒ‡æ•°ç±»èµ„äº§ (ä½¿ç”¨ ComprehensiveAssetReporter)
        if comprehensive_assets:
            logger.info(f"åˆ†ææŒ‡æ•°ç±»èµ„äº§: {', '.join(comprehensive_assets)}")
            if self.comprehensive_reporter is None:
                self.comprehensive_reporter = ComprehensiveAssetReporter()

            if self.enable_parallel:
                # å¹¶å‘æ‰§è¡Œ
                comprehensive_results = self._analyze_assets_parallel(
                    comprehensive_assets,
                    self.comprehensive_reporter.analyze_single_asset
                )
                results['assets'].update(comprehensive_results)
            else:
                # ä¸²è¡Œæ‰§è¡Œ(å‘åå…¼å®¹)
                for asset_key in comprehensive_assets:
                    try:
                        logger.info(f"åˆ†æ {UNIFIED_ASSETS[asset_key]['name']}...")
                        result = self.comprehensive_reporter.analyze_single_asset(asset_key)
                        results['assets'][asset_key] = result
                    except Exception as e:
                        logger.error(f"åˆ†æ {asset_key} å¤±è´¥: {str(e)}")
                        results['assets'][asset_key] = {
                            'error': str(e),
                            'asset_name': UNIFIED_ASSETS[asset_key]['name']
                        }

        # åˆ†ææ¿å—ç±»èµ„äº§ (ä½¿ç”¨ SectorReporter)
        if sector_assets:
            logger.info(f"åˆ†ææ¿å—ç±»èµ„äº§: {', '.join(sector_assets)}")
            if self.sector_reporter is None:
                self.sector_reporter = SectorReporter()

            if self.enable_parallel:
                # å¹¶å‘æ‰§è¡Œ
                sector_results = self._analyze_assets_parallel(
                    sector_assets,
                    self.sector_reporter.analyze_single_sector
                )
                results['assets'].update(sector_results)
            else:
                # ä¸²è¡Œæ‰§è¡Œ(å‘åå…¼å®¹)
                for asset_key in sector_assets:
                    try:
                        logger.info(f"åˆ†æ {UNIFIED_ASSETS[asset_key]['name']}...")
                        result = self.sector_reporter.analyze_single_sector(asset_key)
                        results['assets'][asset_key] = result
                    except Exception as e:
                        logger.error(f"åˆ†æ {asset_key} å¤±è´¥: {str(e)}")
                        results['assets'][asset_key] = {
                            'error': str(e),
                            'asset_name': UNIFIED_ASSETS[asset_key]['name']
                        }

        logger.info("æ‰€æœ‰èµ„äº§åˆ†æå®Œæˆ")
        return results

    def _analyze_assets_parallel(
        self,
        asset_keys: List[str],
        analyzer_func: callable
    ) -> Dict[str, Any]:
        """
        å¹¶å‘åˆ†æå¤šä¸ªèµ„äº§

        Args:
            asset_keys: èµ„äº§ä»£ç åˆ—è¡¨
            analyzer_func: åˆ†æå‡½æ•°(æ¥å—asset_key,è¿”å›ç»“æœå­—å…¸)

        Returns:
            {asset_key: result} å­—å…¸
        """
        results = {}

        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_asset = {
                executor.submit(analyzer_func, asset_key): asset_key
                for asset_key in asset_keys
            }

            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_asset):
                asset_key = future_to_asset[future]
                try:
                    result = future.result()
                    results[asset_key] = result
                    logger.info(f"âœ“ {UNIFIED_ASSETS[asset_key]['name']} åˆ†æå®Œæˆ")
                except Exception as e:
                    logger.error(f"âœ— {asset_key} åˆ†æå¤±è´¥: {str(e)}")
                    results[asset_key] = {
                        'error': str(e),
                        'asset_name': UNIFIED_ASSETS[asset_key]['name']
                    }

        return results

    def format_report(
        self,
        results: dict,
        format_type: str = 'markdown',
        positions: list = None,
        market_data: dict = None
    ) -> str:
        """
        æ ¼å¼åŒ–æŠ¥å‘Š

        ç›´æ¥è°ƒç”¨åŸæœ‰æŠ¥å‘Šç”Ÿæˆå™¨çš„æ–¹æ³•,ç¡®ä¿æ•°æ®å®Œæ•´å±•ç¤º

        Args:
            results: åˆ†æç»“æœ
            format_type: æŠ¥å‘Šæ ¼å¼ ('text' æˆ– 'markdown')
            positions: æŒä»“æ•°æ®åˆ—è¡¨(å¯é€‰)
            market_data: å¸‚åœºæ•°æ®(å¯é€‰)

        Returns:
            æ ¼å¼åŒ–åçš„æŠ¥å‘Šæ–‡æœ¬
        """
        lines = []

        # 1. æŠ¥å‘Šå¤´éƒ¨
        if format_type == 'markdown':
            lines.append("# ğŸ“Š å¸‚åœºæ´å¯ŸæŠ¥å‘Š")
            lines.append("")
            lines.append(f"**ç”Ÿæˆæ—¶é—´**: {results['date']}")
            lines.append("")
            lines.append("---")
            lines.append("")
        else:
            lines.append("=" * 80)
            lines.append("å¸‚åœºæ´å¯ŸæŠ¥å‘Š".center(80))
            lines.append(f"ç”Ÿæˆæ—¶é—´: {results['date']}".center(80))
            lines.append("=" * 80)
            lines.append("")

        # 2. ğŸ¯ ä»Šæ—¥æ“ä½œå»ºè®® (æå‰åˆ°æœ€å‰é¢)
        investment_advice = self._generate_investment_advice_section(results, format_type)
        lines.append(investment_advice)

        # 3. ğŸ”¥ ä»Šæ—¥å¸‚åœºå¤§ç›˜åˆ†æ (æ–°å¢) - è¿”å›(æ–‡æœ¬, market_data)å…ƒç»„
        market_overview, extracted_market_data = self._generate_market_overview_section(results, format_type)
        lines.append(market_overview)

        # 4. ========== æˆ‘çš„æŒä»“åˆ†æ (æ”¾åœ¨å¸‚åœºå¤§ç›˜åˆ†æåé¢) ==========
        if format_type == 'markdown' and positions is not None:
            try:
                logger.info(f"å¼€å§‹ç”ŸæˆæŒä»“åˆ†æ, æŒä»“æ•°: {len(positions)}")
                # åˆ›å»ºæŒä»“æŠ¥å‘Šç”Ÿæˆå™¨
                position_generator = DailyPositionReportGenerator()
                logger.info("æŒä»“æŠ¥å‘Šç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸ")

                # ç”ŸæˆæŒä»“åˆ†æéƒ¨åˆ† - ä½¿ç”¨ä»å¸‚åœºå¤§ç›˜åˆ†æä¸­æå–çš„market_data
                position_section = position_generator.generate_my_position_section(
                    positions=positions,
                    market_data=extracted_market_data,
                    market_results=results
                )
                logger.info(f"æŒä»“åˆ†æç”ŸæˆæˆåŠŸ, é•¿åº¦: {len(position_section)}")

                lines.append(position_section)
            except Exception as e:
                logger.error(f"ç”ŸæˆæŒä»“åˆ†æå¤±è´¥: {e}", exc_info=True)
                lines.append("## ğŸ’¼ ã€æˆ‘çš„æŒä»“åˆ†æã€‘")
                lines.append("")
                lines.append(f"âš ï¸ æŒä»“åˆ†æç”Ÿæˆå¤±è´¥: {str(e)}")
                lines.append("")
                lines.append("è¯·æ£€æŸ¥æ—¥å¿—äº†è§£è¯¦ç»†é”™è¯¯ä¿¡æ¯")
                lines.append("")

        # 5. ç»Ÿè®¡ä¿¡æ¯ (ç§»åˆ°æ ‡çš„æ±‡æ€»é‡Œé¢)
        total_count = len(results['assets'])
        success_count = sum(1 for data in results['assets'].values() if 'error' not in data)
        fail_count = total_count - success_count

        # 6. ç”Ÿæˆæ±‡æ€»è¡¨æ ¼ (åŒ…å«åˆ†ææ¦‚è§ˆ)
        if format_type == 'markdown':
            summary_table = self._generate_summary_table(results)
            if summary_table:
                lines.append("## ğŸ“Š æ ‡çš„æ±‡æ€»")
                lines.append("")
                lines.append("### ğŸ“‹ åˆ†ææ¦‚è§ˆ")
                lines.append("")
                lines.append(f"- **æ€»èµ„äº§æ•°**: {total_count}")
                lines.append(f"- **æˆåŠŸåˆ†æ**: {success_count}")
                lines.append(f"- **å¤±è´¥æ•°**: {fail_count}")
                lines.append("")
                lines.append(summary_table)
                lines.append("")
            lines.append("---")
            lines.append("")
        else:
            lines.append(f"æ€»èµ„äº§æ•°: {total_count}")
            lines.append(f"æˆåŠŸåˆ†æ: {success_count}")
            lines.append(f"å¤±è´¥æ•°: {fail_count}")
            lines.append("")
            lines.append("=" * 80)
            lines.append("")

        # 6. ========== æœºæ„çº§æ ¸å¿ƒæŒ‡æ ‡ (Phase 3.3) ==========
        if HAS_CORE_ANALYZERS and self.valuation_analyzer:
            if format_type == 'markdown':
                lines.append("## ğŸ›ï¸ æœºæ„çº§æ ¸å¿ƒæŒ‡æ ‡")
                lines.append("")
                lines.append("**è¯´æ˜**: åŸºäºæ²ªæ·±300æŒ‡æ•°ï¼Œè¿™ä¸‰ä¸ªæŒ‡æ ‡æ˜¯æœºæ„æŠ•èµ„è€…é¿å…é«˜ä½è¢«å¥—çš„æ ¸å¿ƒå·¥å…·")
                lines.append("")
            else:
                lines.append("-" * 80)
                lines.append("æœºæ„çº§æ ¸å¿ƒæŒ‡æ ‡ (æ²ªæ·±300)")
                lines.append("-" * 80)
                lines.append("")

            try:
                # 1. ä¼°å€¼åˆ†æ
                val_data = self.valuation_analyzer.calculate_valuation_percentile(
                    index_code='000300',  # æ²ªæ·±300
                    periods=[1260, 2520]  # 5å¹´/10å¹´
                )

                if val_data and 'error' not in val_data and val_data.get('percentiles'):
                    if format_type == 'markdown':
                        lines.append("### ğŸ“Š ä¼°å€¼åˆ†æ (PE/PBå†å²åˆ†ä½æ•°)")
                        lines.append("")
                        lines.append("| å‘¨æœŸ | PEåˆ†ä½æ•° | PBåˆ†ä½æ•° | ä¼°å€¼æ°´å¹³ |")
                        lines.append("|------|---------|---------|---------|")
                    else:
                        lines.append("ä¼°å€¼åˆ†æ:")

                    period_names = {'1260': '5å¹´', '2520': '10å¹´'}
                    for period_days, period_name in period_names.items():
                        if period_days in val_data['percentiles']:
                            pct_data = val_data['percentiles'][period_days]
                            pe_pct = pct_data.get('pe_percentile', 0) * 100
                            pb_pct = pct_data.get('pb_percentile', 0) * 100
                            level = pct_data.get('level', 'æœªçŸ¥')

                            if format_type == 'markdown':
                                level_emoji = {'æä½ä¼°': 'ğŸŸ¢ğŸŸ¢', 'ä½ä¼°': 'ğŸŸ¢', 'åˆç†': 'ğŸŸ¡', 'é«˜ä¼°': 'ğŸ”´', 'æé«˜ä¼°': 'ğŸ”´ğŸ”´'}.get(level, 'âšª')
                                lines.append(f"| {period_name} | {pe_pct:.1f}% | {pb_pct:.1f}% | {level_emoji} {level} |")
                            else:
                                lines.append(f"  {period_name}: PEåˆ†ä½{pe_pct:.1f}%, PBåˆ†ä½{pb_pct:.1f}% - {level}")

                    lines.append("")

                # 2. å¸‚åœºå®½åº¦åˆ†æ
                breadth_data = self.breadth_analyzer.comprehensive_analysis()
                if breadth_data and 'error' not in breadth_data:
                    metrics = breadth_data.get('metrics', {})
                    strength_analysis = breadth_data.get('strength_analysis', {})

                    if metrics:
                        if format_type == 'markdown':
                            lines.append("### ğŸ“ˆ å¸‚åœºå®½åº¦ (æ–°é«˜æ–°ä½)")
                            lines.append("")
                            lines.append("| å‘¨æœŸ | åˆ›æ–°é«˜ | åˆ›æ–°ä½ | å®½åº¦æ¯” | å¸‚åœºå¼ºåº¦ |")
                            lines.append("|------|--------|--------|--------|----------|")
                        else:
                            lines.append("å¸‚åœºå®½åº¦:")

                        # 20æ—¥æ•°æ®
                        if 'high20' in metrics and 'low20' in metrics:
                            high20 = metrics['high20']
                            low20 = metrics['low20']
                            ratio20 = metrics.get('high_low_ratio_20', 1.0)
                            strength20 = strength_analysis.get('20day_strength', 'ä¸­æ€§')

                            if format_type == 'markdown':
                                strength_emoji = {'å¼ºåŠ¿': 'ğŸŸ¢', 'å¥åº·': 'ğŸŸ¢', 'ä¸­æ€§': 'ğŸŸ¡', 'å¼±åŠ¿': 'ğŸ”´', 'æå¼±': 'ğŸ”´ğŸ”´'}.get(strength20, 'âšª')
                                lines.append(f"| 20æ—¥ | {high20} | {low20} | {ratio20:.2f} | {strength_emoji} {strength20} |")
                            else:
                                lines.append(f"  20æ—¥: æ–°é«˜{high20}, æ–°ä½{low20}, æ¯”å€¼{ratio20:.2f} - {strength20}")

                        # 60æ—¥æ•°æ®
                        if 'high60' in metrics and 'low60' in metrics:
                            high60 = metrics['high60']
                            low60 = metrics['low60']
                            ratio60 = metrics.get('high_low_ratio_60', 1.0)
                            strength60 = strength_analysis.get('60day_strength', 'ä¸­æ€§')

                            if format_type == 'markdown':
                                strength_emoji = {'å¼ºåŠ¿': 'ğŸŸ¢', 'å¥åº·': 'ğŸŸ¢', 'ä¸­æ€§': 'ğŸŸ¡', 'å¼±åŠ¿': 'ğŸ”´', 'æå¼±': 'ğŸ”´ğŸ”´'}.get(strength60, 'âšª')
                                lines.append(f"| 60æ—¥ | {high60} | {low60} | {ratio60:.2f} | {strength_emoji} {strength60} |")
                            else:
                                lines.append(f"  60æ—¥: æ–°é«˜{high60}, æ–°ä½{low60}, æ¯”å€¼{ratio60:.2f} - {strength60}")

                        lines.append("")

                # 3. èèµ„èåˆ¸åˆ†æ
                margin_data = self.margin_analyzer.comprehensive_analysis(market='sse')
                if margin_data and 'error' not in margin_data:
                    metrics = margin_data.get('metrics', {})
                    sentiment_analysis = margin_data.get('sentiment_analysis', {})

                    if metrics:
                        margin_balance = metrics.get('latest_margin_balance', 0)
                        sentiment_score = sentiment_analysis.get('sentiment_score', 50)
                        sentiment_level = sentiment_analysis.get('sentiment_level', 'ä¸­æ€§')
                        trend = metrics.get('trend', 'å¹³ç¨³')

                        if format_type == 'markdown':
                            lines.append("### ğŸ’° èèµ„èåˆ¸ (å¸‚åœºæƒ…ç»ª)")
                            lines.append("")
                            lines.append(f"- **èèµ„ä½™é¢**: Â¥{margin_balance/1e8:.0f}äº¿")
                            lines.append(f"- **è¶‹åŠ¿**: {trend}")
                            lines.append(f"- **æƒ…ç»ªå¾—åˆ†**: {sentiment_score:.0f}/100")
                            lines.append(f"- **æƒ…ç»ªæ°´å¹³**: {sentiment_level}")
                        else:
                            lines.append("èèµ„èåˆ¸:")
                            lines.append(f"  èèµ„ä½™é¢: {margin_balance/1e8:.0f}äº¿ ({trend})")
                            lines.append(f"  æƒ…ç»ªå¾—åˆ†: {sentiment_score:.0f}/100 ({sentiment_level})")

                        lines.append("")

                if format_type == 'markdown':
                    lines.append("---")
                    lines.append("")
                else:
                    lines.append("-" * 80)
                    lines.append("")

            except Exception as e:
                logger.error(f"æœºæ„çº§æ ¸å¿ƒæŒ‡æ ‡åˆ†æå¤±è´¥: {str(e)}")
                if format_type == 'markdown':
                    lines.append(f"âš ï¸ æœºæ„çº§æ ¸å¿ƒæŒ‡æ ‡åˆ†æå¤±è´¥: {str(e)}")
                    lines.append("")
                    lines.append("---")
                    lines.append("")

        # åˆ†ç»„æ•´ç†æŠ¥å‘Šæ•°æ®
        comprehensive_report = {'assets': {}}
        sector_reports = []

        for asset_key, data in results['assets'].items():
            if 'error' in data:
                continue

            config = UNIFIED_ASSETS[asset_key]
            if config['analyzer_type'] == 'comprehensive':
                comprehensive_report['assets'][asset_key] = data
            elif config['analyzer_type'] == 'sector':
                sector_reports.append((asset_key, data, config))

        # ç”ŸæˆæŒ‡æ•°ç±»èµ„äº§æŠ¥å‘Š (ä½¿ç”¨ ComprehensiveAssetReporter)
        if comprehensive_report['assets'] and self.comprehensive_reporter:
            comprehensive_report['timestamp'] = results['timestamp']
            comprehensive_report['date'] = results['date']

            if format_type == 'markdown':
                lines.append(self.comprehensive_reporter.format_markdown_report(comprehensive_report))
            else:
                lines.append(self.comprehensive_reporter.format_text_report(comprehensive_report))

        # ç”Ÿæˆæ¿å—ç±»èµ„äº§æŠ¥å‘Š (ä½¿ç”¨ SectorReporter)
        if sector_reports and self.sector_reporter:
            for asset_key, data, config in sector_reports:
                # æ„é€ å•ä¸ªæ¿å—çš„æŠ¥å‘Šæ•°æ®
                single_sector_report = {
                    'timestamp': results['timestamp'],
                    'date': results['date'],
                    'sectors': {asset_key: data}
                }

                if format_type == 'markdown':
                    # SectorReporter åªæœ‰ format_text_report,æˆ‘ä»¬éœ€è¦æ‰‹åŠ¨ç”Ÿæˆ markdown
                    lines.append(self._format_sector_markdown(asset_key, data, config))
                else:
                    lines.append(self.sector_reporter.format_text_report(single_sector_report))

        # å¤±è´¥çš„èµ„äº§
        if fail_count > 0:
            if format_type == 'markdown':
                lines.append("## âš ï¸ åˆ†æå¤±è´¥")
                lines.append("")
                for asset_key, data in results['assets'].items():
                    if 'error' in data:
                        lines.append(f"- **{data.get('asset_name', asset_key)}**: {data['error']}")
                lines.append("")
            else:
                lines.append("-" * 80)
                lines.append("åˆ†æå¤±è´¥")
                lines.append("-" * 80)
                for asset_key, data in results['assets'].items():
                    if 'error' in data:
                        lines.append(f"{data.get('asset_name', asset_key)}: {data['error']}")
                lines.append("")

        # æŠ¥å‘Šå°¾éƒ¨
        if format_type == 'markdown':
            lines.append("## ğŸ“– ã€æŠ•èµ„çºªå¾‹ã€‘")
            lines.append("")
            lines.append("è¯¦ç»†çš„æŠ•èµ„ç­–ç•¥åŸåˆ™å’Œçºªå¾‹,è¯·å‚è€ƒ:")
            lines.append("ğŸ‘‰ [æŠ•èµ„çºªå¾‹æ‰‹å†Œ](../../docs/æŠ•èµ„çºªå¾‹æ‰‹å†Œ.md)")
            lines.append("")
            lines.append("**å¿«é€Ÿæé†’**:")
            lines.append("- âœ… **ä»“ä½ç®¡ç†**: ä¿æŒ5-9æˆ,ç•™è‡³å°‘1æˆåº”å¯¹é»‘å¤©é¹…")
            lines.append("- âœ… **æ ‡çš„é€‰æ‹©**: é›†ä¸­3-5åª,å•ä¸€æ ‡çš„â‰¤20%")
            lines.append("- âœ… **æŠ•èµ„èŠ‚å¥**: é•¿çº¿åº•ä»“+æ³¢æ®µåŠ å‡ä»“")
            lines.append("- âœ… **æ”¶ç›Šç›®æ ‡**: å¹´åŒ–15%,ç©¿è¶Šç‰›ç†Š")
            lines.append("- âœ… **çºªå¾‹æ‰§è¡Œ**: å…ˆåˆ¶å®šæ–¹æ¡ˆâ†’æ‰§è¡Œâ†’è¿­ä»£,ä¸æƒ…ç»ªåŒ–æ“ä½œ")
            lines.append("")
            lines.append("---")
            lines.append("")
            lines.append("**å…è´£å£°æ˜**: æœ¬æŠ¥å‘Šä»…ä¾›å‚è€ƒ,ä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚æŠ•èµ„æœ‰é£é™©,å…¥å¸‚éœ€è°¨æ…ã€‚")
            lines.append("")
            lines.append(f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {results['date']}*")
        else:
            lines.append("=" * 80)
            lines.append("å…è´£å£°æ˜: æœ¬æŠ¥å‘Šä»…ä¾›å‚è€ƒ,ä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚æŠ•èµ„æœ‰é£é™©,å…¥å¸‚éœ€è°¨æ…ã€‚")
            lines.append("=" * 80)

        return '\n'.join(lines)

    def _generate_summary_table(self, results: dict) -> str:
        """ç”Ÿæˆæ‰€æœ‰æ ‡çš„æ±‡æ€»è¡¨æ ¼"""
        lines = []

        # è¡¨å¤´ (æ·»åŠ æŒæœ‰å»ºè®®åˆ—)
        lines.append("| æ ‡çš„åç§° | å½“å‰ä»·æ ¼ | æ¶¨è·Œå¹… | æ–¹å‘åˆ¤æ–­ | å»ºè®®ä»“ä½ | 20æ—¥ä¸Šæ¶¨æ¦‚ç‡ | é£é™©ç­‰çº§ | æŒæœ‰å»ºè®® |")
        lines.append("|----------|----------|--------|----------|----------|--------------|----------|----------|")

        # éå†æ‰€æœ‰èµ„äº§
        for asset_key, data in results['assets'].items():
            if 'error' in data:
                continue

            config = UNIFIED_ASSETS[asset_key]

            # æ ‡çš„åç§°
            if config['analyzer_type'] == 'comprehensive':
                asset_name = data.get('asset_name', config['name'])
            else:
                asset_name = data.get('sector_name', config['name'])

            # å½“å‰ä»·æ ¼å’Œæ¶¨è·Œå¹… - ä¿®å¤å­—æ®µåç§°
            # comprehensive ç±»å‹ä½¿ç”¨ 'historical_analysis', sector ç±»å‹ä¹Ÿä½¿ç”¨ 'historical_analysis'
            hist = data.get('historical_analysis', {})

            current_price = hist.get('current_price', 0)
            change_pct = hist.get('current_change_pct', 0)
            # ä¸­å›½è‚¡å¸‚ä¹ æƒ¯: çº¢æ¶¨ç»¿è·Œ
            change_emoji = "ğŸ”´" if change_pct >= 0 else "ğŸŸ¢"

            # ç»¼åˆåˆ¤æ–­
            judgment = data.get('comprehensive_judgment', {})
            direction = judgment.get('direction', 'N/A')
            position = judgment.get('recommended_position', 'N/A')

            # æ–¹å‘åˆ¤æ–­emoji
            direction_map = {
                'å¼ºçƒˆçœ‹å¤š': 'âœ…âœ…',
                'çœ‹å¤š': 'âœ…',
                'ä¸­æ€§åå¤š': 'âš–ï¸',
                'ä¸­æ€§': 'âš–ï¸',
                'çœ‹ç©º': 'ğŸ”´'
            }
            direction_with_emoji = f"{direction}{direction_map.get(direction, '')}"

            # 20æ—¥ä¸Šæ¶¨æ¦‚ç‡ (comprehensive å’Œ sector ä½¿ç”¨ç›¸åŒå­—æ®µ)
            stats_20d = hist.get('20d', {})
            up_prob_20d = stats_20d.get('up_prob', 0)
            # ç»™ä¸Šæ¶¨æ¦‚ç‡æ·»åŠ é¢œè‰²: >=60%çº¢è‰²(çœ‹æ¶¨), <40%ç»¿è‰²(çœ‹è·Œ), 40-60%æ— è‰²
            if up_prob_20d >= 0.6:
                prob_emoji = "ğŸ”´"
            elif up_prob_20d < 0.4:
                prob_emoji = "ğŸŸ¢"
            else:
                prob_emoji = ""
            prob_display = f"{up_prob_20d:.1%} {prob_emoji}" if prob_emoji else f"{up_prob_20d:.1%}"

            # é£é™©ç­‰çº§
            risk = data.get('risk_assessment', {})
            risk_level = risk.get('risk_level', 'N/A')
            risk_emoji_map = {
                'æé«˜é£é™©': 'ğŸ”´ğŸ”´ğŸ”´',
                'é«˜é£é™©': 'ğŸ”´ğŸ”´',
                'ä¸­é£é™©': 'âš ï¸',
                'ä½é£é™©': 'âœ…'
            }
            risk_with_emoji = f"{risk_emoji_map.get(risk_level, '')} {risk_level}"

            # æŒæœ‰å»ºè®® - ä» strategies ä¸­æå–åŒ…å«"æŒæœ‰"çš„å»ºè®®
            strategies = judgment.get('strategies', [])
            hold_suggestion = '-'
            for strategy in strategies:
                # åŒ¹é…åŒ…å«"æŒæœ‰"å…³é”®è¯çš„å»ºè®®
                if 'æŒæœ‰' in strategy:
                    hold_suggestion = strategy
                    break

            # ç”Ÿæˆè¡¨æ ¼è¡Œ (æ·»åŠ æŒæœ‰å»ºè®®åˆ—)
            lines.append(
                f"| {asset_name} | {current_price:.2f} | "
                f"{change_pct:+.2f}% {change_emoji} | {direction_with_emoji} | {position} | "
                f"{prob_display} | {risk_with_emoji} | {hold_suggestion} |"
            )

        return '\n'.join(lines)

    def analyze_market_state(self, market_data: dict) -> dict:
        """
        åˆ†æå¸‚åœºçŠ¶æ€ï¼Œç»¼åˆåˆ¤æ–­å½“å‰å¤„äºä»€ä¹ˆå¸‚åœºç¯å¢ƒ

        åŸºäº4ä¸ªç»´åº¦:
        1. çŸ­æœŸè¶‹åŠ¿: å½“æ—¥å¹³å‡æ¶¨è·Œå¹…
        2. é•¿æœŸè¶‹åŠ¿: å¹´åˆè‡³ä»Šç´¯è®¡æ¶¨å¹…
        3. å¸‚åœºå®½åº¦: ä¸»è¦æŒ‡æ•°å…±æŒ¯æƒ…å†µ

        Args:
            market_data: å¸‚åœºæ•°æ®

        Returns:
            å¸‚åœºçŠ¶æ€åˆ†æç»“æœ
        """
        indices = market_data.get('indices', {})
        if not indices:
            return {'state': 'æœªçŸ¥', 'confidence': 0, 'suggestion': 'æ•°æ®ä¸è¶³',
                    'recommended_position': (0.60, 0.75)}

        # ========== 1. çŸ­æœŸè¶‹åŠ¿åˆ¤æ–­(å½“æ—¥æ¶¨è·Œ) ==========
        avg_change = sum(idx.get('change_pct', 0) for idx in indices.values()) / len(indices)

        short_term_score = 0
        if avg_change > 1.5:
            short_term_score = 2  # å¼ºåŠ¿ä¸Šæ¶¨
        elif avg_change > 0.5:
            short_term_score = 1  # æ¸©å’Œä¸Šæ¶¨
        elif avg_change > -0.5:
            short_term_score = 0  # éœ‡è¡
        elif avg_change > -1.5:
            short_term_score = -1  # æ¸©å’Œä¸‹è·Œ
        else:
            short_term_score = -2  # å¼ºåŠ¿ä¸‹è·Œ

        # ========== 2. é•¿æœŸè¶‹åŠ¿åˆ¤æ–­(å¹´åˆè‡³ä»Šæ¶¨å¹…) ==========
        # åŸºå‡†ç‚¹ä½(2025-01-01)
        benchmark_points = {
            'HS300': 3145.0,
            'CYBZ': 2060.0,
            'KECHUANG50': 955.0
        }

        ytd_gains = []
        for key, idx in indices.items():
            current = idx.get('current', 0)
            if key in benchmark_points and current > 0:
                base = benchmark_points[key]
                ytd_gain = (current - base) / base
                ytd_gains.append(ytd_gain)

        avg_ytd_gain = sum(ytd_gains) / len(ytd_gains) if ytd_gains else 0

        long_term_score = 0
        if avg_ytd_gain > 0.30:  # å¹´å†…æ¶¨è¶…30%
            long_term_score = 2  # å¼ºåŠ¿ç‰›å¸‚
        elif avg_ytd_gain > 0.15:  # å¹´å†…æ¶¨15%-30%
            long_term_score = 1  # æ¸©å’Œç‰›å¸‚
        elif avg_ytd_gain > -0.10:  # å¹´å†…Â±10%ä»¥å†…
            long_term_score = 0  # éœ‡è¡
        elif avg_ytd_gain > -0.20:  # å¹´å†…è·Œ10%-20%
            long_term_score = -1  # æ¸©å’Œç†Šå¸‚
        else:  # å¹´å†…è·Œè¶…20%
            long_term_score = -2  # æ·±åº¦ç†Šå¸‚

        # ========== 3. å¸‚åœºå®½åº¦(æŒ‡æ•°å…±æŒ¯) ==========
        positive_count = sum(1 for idx in indices.values() if idx.get('change_pct', 0) > 0)
        total_count = len(indices)
        positive_ratio = positive_count / total_count if total_count > 0 else 0.5

        breadth_score = 0
        if positive_ratio >= 0.8:  # 80%ä»¥ä¸Šä¸Šæ¶¨
            breadth_score = 2
        elif positive_ratio >= 0.6:  # 60%-80%ä¸Šæ¶¨
            breadth_score = 1
        elif positive_ratio >= 0.4:  # 40%-60%
            breadth_score = 0
        elif positive_ratio >= 0.2:  # 20%-40%ä¸Šæ¶¨
            breadth_score = -1
        else:  # 20%ä»¥ä¸‹ä¸Šæ¶¨
            breadth_score = -2

        # ========== 4. ç»¼åˆè¯„åˆ†ä¸çŠ¶æ€åˆ¤æ–­ ==========
        # çŸ­æœŸæƒé‡30%, é•¿æœŸæƒé‡50%, å¸‚åœºå®½åº¦20%
        total_score = short_term_score * 0.3 + long_term_score * 0.5 + breadth_score * 0.2

        # æ ¹æ®ç»¼åˆè¯„åˆ†åˆ¤æ–­å¸‚åœºçŠ¶æ€
        if total_score >= 1.2:
            # å¼ºåŠ¿ç‰›å¸‚ä¸Šå‡æœŸ
            state = 'ç‰›å¸‚ä¸Šå‡æœŸ'
            emoji = 'ğŸš€'
            suggestion = 'ç§¯æé…ç½®,æŠŠæ¡ä¸Šæ¶¨æœºä¼š'
            recommended_position = (0.70, 0.90)
            confidence = 80
            phase = 'bull_rally'
        elif total_score >= 0.5:
            # ç‰›å¸‚è°ƒæ•´/éœ‡è¡æœŸ
            state = 'ç‰›å¸‚éœ‡è¡æœŸ'
            emoji = 'ğŸ“ˆ'
            suggestion = 'ç»´æŒè¾ƒé«˜ä»“ä½,é€¢ä½åŠ ä»“'
            recommended_position = (0.60, 0.80)
            confidence = 70
            phase = 'bull_consolidation'
        elif total_score >= -0.3:
            # éœ‡è¡å¸‚
            state = 'éœ‡è¡å¸‚'
            emoji = 'ğŸŸ¡'
            suggestion = 'æ§åˆ¶ä»“ä½,é«˜æŠ›ä½å¸'
            recommended_position = (0.50, 0.70)
            confidence = 65
            phase = 'sideways'
        elif total_score >= -0.8:
            # ç†Šå¸‚åå¼¹
            state = 'ç†Šå¸‚åå¼¹æœŸ'
            emoji = 'âš ï¸'
            suggestion = 'è°¨æ…å‚ä¸åå¼¹,ä¿ç•™ç°é‡‘'
            recommended_position = (0.40, 0.60)
            confidence = 60
            phase = 'bear_rally'
        else:
            # ç†Šå¸‚ä¸‹è·ŒæœŸ
            state = 'ç†Šå¸‚ä¸‹è·ŒæœŸ'
            emoji = 'ğŸ“‰'
            suggestion = 'ä¸¥æ§ä»“ä½,ä¿ç•™ç°é‡‘ä¸ºä¸»'
            recommended_position = (0.30, 0.50)
            confidence = 75
            phase = 'bear_decline'

        return {
            'state': state,
            'phase': phase,
            'emoji': emoji,
            'avg_change': avg_change,
            'avg_ytd_gain': avg_ytd_gain,
            'positive_ratio': positive_ratio,
            'total_score': total_score,
            'confidence': confidence,
            'suggestion': suggestion,
            'recommended_position': recommended_position,
            'detail_scores': {
                'short_term': short_term_score,
                'long_term': long_term_score,
                'breadth': breadth_score
            }
        }

    def _generate_market_overview_section(self, results: dict, format_type: str) -> tuple:
        """
        ç”Ÿæˆä»Šæ—¥å¸‚åœºå¤§ç›˜åˆ†æ

        Args:
            results: åˆ†æç»“æœ
            format_type: æŠ¥å‘Šæ ¼å¼

        Returns:
            (å¸‚åœºå¤§ç›˜åˆ†ææ–‡æœ¬, å¸‚åœºæ•°æ®å­—å…¸) å…ƒç»„
        """
        lines = []
        market_data = None  # åˆå§‹åŒ–è¿”å›å€¼

        if format_type == 'markdown':
            lines.append("## ğŸ”¥ ä»Šæ—¥å¸‚åœºå¤§ç›˜åˆ†æ")
            lines.append("")
        else:
            lines.append("-" * 80)
            lines.append("ä»Šæ—¥å¸‚åœºå¤§ç›˜åˆ†æ")
            lines.append("-" * 80)
            lines.append("")

        try:
            # æå–æ ¸å¿ƒæŒ‡æ•°æ•°æ®
            index_data = {}
            for key in ['HS300', 'CYBZ', 'KECHUANG50', 'HKTECH']:
                if key in results['assets'] and 'error' not in results['assets'][key]:
                    data = results['assets'][key]
                    hist = data.get('historical_analysis', {})
                    index_data[key] = {
                        'name': data.get('asset_name', key),
                        'price': hist.get('current_price', 0),
                        'change_pct': hist.get('current_change_pct', 0),
                        'direction': data.get('comprehensive_judgment', {}).get('direction', 'N/A')
                    }

            # ç”Ÿæˆå¸‚åœºæ¦‚å†µ
            if format_type == 'markdown':
                lines.append("### ğŸ“ˆ æ ¸å¿ƒæŒ‡æ•°è¡¨ç°")
                lines.append("")
                lines.append("| æŒ‡æ•° | æœ€æ–°ä»·æ ¼ | æ¶¨è·Œå¹… | æ–¹å‘åˆ¤æ–­ |")
                lines.append("|------|----------|--------|----------|")

                for key in ['HS300', 'CYBZ', 'KECHUANG50', 'HKTECH']:
                    if key in index_data:
                        idx = index_data[key]
                        change_emoji = "ğŸ”´" if idx['change_pct'] >= 0 else "ğŸŸ¢"
                        direction_map = {
                            'å¼ºçƒˆçœ‹å¤š': 'âœ…âœ…',
                            'çœ‹å¤š': 'âœ…',
                            'ä¸­æ€§åå¤š': 'âš–ï¸',
                            'ä¸­æ€§': 'âš–ï¸',
                            'çœ‹ç©º': 'ğŸ”´'
                        }
                        direction_emoji = direction_map.get(idx['direction'], '')
                        lines.append(f"| {idx['name']} | {idx['price']:.2f} | {idx['change_pct']:+.2f}% {change_emoji} | {idx['direction']}{direction_emoji} |")

                lines.append("")

            # å¸‚åœºçŠ¶æ€ç»¼åˆåˆ¤æ–­ï¼ˆå¢å¼ºç‰ˆï¼‰
            if index_data:
                # å‡†å¤‡å¸‚åœºæ•°æ®ç”¨äºçŠ¶æ€åˆ†æ
                market_data = {
                    'indices': {
                        key: {
                            'current': data['price'],
                            'change_pct': data['change_pct']
                        }
                        for key, data in index_data.items()
                    }
                }

                # è°ƒç”¨å¸‚åœºçŠ¶æ€åˆ†æ
                market_state = self.analyze_market_state(market_data)

                if format_type == 'markdown':
                    lines.append("### ğŸŒ å¸‚åœºç¯å¢ƒä¸ä»“ä½ç­–ç•¥")
                    lines.append("")
                    lines.append(f"**å½“å‰å¸‚åœºçŠ¶æ€**: {market_state['emoji']} {market_state['state']}")
                    lines.append("")
                    lines.append("**å¤šç»´åº¦åˆ†æ**:")
                    lines.append("")
                    lines.append("| ç»´åº¦ | è¯„åˆ† | æ•°æ® | è¯´æ˜ |")
                    lines.append("|------|------|------|------|")

                    # çŸ­æœŸè¶‹åŠ¿
                    st_score = market_state['detail_scores']['short_term']
                    st_emoji = "ğŸš€" if st_score >= 1 else "ğŸ“ˆ" if st_score > 0 else "â¡ï¸" if st_score == 0 else "ğŸ“‰"
                    st_desc = "å¼ºåŠ¿" if abs(st_score) == 2 else "æ¸©å’Œ" if abs(st_score) == 1 else "éœ‡è¡"
                    lines.append(f"| çŸ­æœŸè¶‹åŠ¿ | {st_score:+.1f} | å½“æ—¥å‡æ¶¨{market_state['avg_change']:+.2f}% | {st_emoji} {st_desc} |")

                    # é•¿æœŸè¶‹åŠ¿
                    lt_score = market_state['detail_scores']['long_term']
                    lt_emoji = "ğŸš€" if lt_score >= 1 else "ğŸ“ˆ" if lt_score > 0 else "â¡ï¸" if lt_score == 0 else "ğŸ“‰"
                    lt_desc = "ç‰›å¸‚" if lt_score >= 1 else "éœ‡è¡" if lt_score == 0 else "ç†Šå¸‚"
                    lines.append(f"| é•¿æœŸè¶‹åŠ¿ | {lt_score:+.1f} | å¹´å†…ç´¯è®¡{market_state['avg_ytd_gain']*100:+.1f}% | {lt_emoji} {lt_desc} |")

                    # å¸‚åœºå®½åº¦
                    br_score = market_state['detail_scores']['breadth']
                    br_emoji = "âœ…" if br_score >= 1 else "ğŸŸ¡" if br_score == 0 else "âŒ"
                    br_desc = "æ™®æ¶¨" if br_score >= 1 else "åˆ†åŒ–" if br_score == 0 else "æ™®è·Œ"
                    lines.append(f"| å¸‚åœºå®½åº¦ | {br_score:+.1f} | {market_state['positive_ratio']*100:.0f}%æŒ‡æ•°ä¸Šæ¶¨ | {br_emoji} {br_desc} |")

                    # ç»¼åˆè¯„åˆ†
                    lines.append(f"| **ç»¼åˆè¯„åˆ†** | **{market_state['total_score']:.2f}** | èŒƒå›´:-2åˆ°+2 | ç½®ä¿¡åº¦: {market_state['confidence']}% |")
                    lines.append("")

                    # æˆ˜ç•¥ä»“ä½å»ºè®®
                    pos_range = market_state['recommended_position']
                    lines.append("**æˆ˜ç•¥ä»“ä½å»ºè®®** (æŒ‰å‘¨è°ƒæ•´):")
                    lines.append("")
                    lines.append(f"- **å»ºè®®ä»“ä½**: {int(pos_range[0]*10)}-{int(pos_range[1]*10)}æˆ ({pos_range[0]*100:.0f}%-{pos_range[1]*100:.0f}%)")
                    lines.append(f"- **ç°é‡‘å‚¨å¤‡**: {int((1-pos_range[1])*10)}-{int((1-pos_range[0])*10)}æˆ ({(1-pos_range[1])*100:.0f}%-{(1-pos_range[0])*100:.0f}%)")
                    lines.append(f"- **æ“ä½œç­–ç•¥**: {market_state['suggestion']}")
                    lines.append(f"- **è°ƒæ•´å‘¨æœŸ**: æ¯å‘¨å¤ç›˜åè°ƒæ•´")
                    lines.append("")

                    # åŠ¨æ€ä»“ä½å‚è€ƒ
                    lines.append("**åŠ¨æ€ä»“ä½å‚è€ƒ**:")
                    lines.append("- ğŸš€ ç‰›å¸‚ä¸Šå‡æœŸ: 7-9æˆ")
                    lines.append("- ğŸ“ˆ ç‰›å¸‚éœ‡è¡æœŸ: 6-8æˆ")
                    lines.append("- ğŸŸ¡ éœ‡è¡å¸‚: 5-7æˆ")
                    lines.append("- âš ï¸ ç†Šå¸‚åå¼¹æœŸ: 4-6æˆ")
                    lines.append("- ğŸ“‰ ç†Šå¸‚ä¸‹è·ŒæœŸ: 3-5æˆ")

                    # æ ‡æ³¨å½“å‰çŠ¶æ€
                    phase_marks = {
                        'bull_rally': ' â† å½“å‰',
                        'bull_consolidation': ' â† å½“å‰',
                        'sideways': ' â† å½“å‰',
                        'bear_rally': ' â† å½“å‰',
                        'bear_decline': ' â† å½“å‰'
                    }
                    if market_state['phase'] in phase_marks:
                        # æ‰¾åˆ°å¯¹åº”è¡Œå¹¶æ·»åŠ æ ‡è®°
                        for i in range(len(lines) - 5, len(lines)):
                            if market_state['state'] in lines[i]:
                                lines[i] += phase_marks[market_state['phase']]
                                break

                    lines.append("")

            lines.append("---")
            lines.append("")

        except Exception as e:
            logger.error(f"ç”Ÿæˆå¸‚åœºå¤§ç›˜åˆ†æå¤±è´¥: {e}")
            if format_type == 'markdown':
                lines.append("âš ï¸ å¸‚åœºå¤§ç›˜åˆ†æç”Ÿæˆå¤±è´¥")
                lines.append("")
                lines.append("---")
                lines.append("")

        return '\n'.join(lines), market_data

    def _generate_investment_advice_section(self, results: dict, format_type: str) -> str:
        """
        ç”ŸæˆæŠ•èµ„å»ºè®®æ 

        Args:
            results: åˆ†æç»“æœ
            format_type: æŠ¥å‘Šæ ¼å¼

        Returns:
            æŠ•èµ„å»ºè®®æ–‡æœ¬
        """
        lines = []

        if format_type == 'markdown':
            lines.append("## ğŸ¯ ã€å»ºè®®ã€‘")
            lines.append("")
            lines.append("æ ¹æ®ä½ çš„äº¤æ˜“ç³»ç»Ÿç”Ÿæˆçš„25ä¸ªèµ„äº§åˆ†ææŠ¥å‘Šï¼Œæˆ‘æ¥ä¸ºä½ ç­›é€‰å½“å‰å»ºè®®å‚ä¸çš„æ ‡çš„ï¼š")
            lines.append("")
        else:
            lines.append("=" * 80)
            lines.append("æŠ•èµ„å»ºè®®")
            lines.append("=" * 80)

        try:
            # ä¸ºæ¯ä¸ªèµ„äº§ç”Ÿæˆå»ºè®®
            assets_advice = []
            for asset_key, data in results['assets'].items():
                if 'error' in data:
                    continue

                # å‡†å¤‡èµ„äº§æ•°æ®
                asset_data = {
                    'key': asset_key,
                    'name': data.get('asset_name', data.get('sector_name', asset_key)),
                    'technical_analysis': self._extract_technical_data(data),
                    'position_analysis': self._extract_position_data(data),
                    'volume_analysis': self._extract_volume_data(data),
                    'historical_analysis': data.get('historical_analysis', {}),
                    'overall_judgment': data.get('comprehensive_judgment', {})
                }

                advice = self.investment_advisor.generate_asset_advice(asset_data)
                # æ·»åŠ æ–¹å‘åˆ¤æ–­å­—æ®µ
                advice['direction'] = data.get('comprehensive_judgment', {}).get('direction', 'ä¸­æ€§')
                assets_advice.append(advice)

            # ç”ŸæˆæŠ•èµ„ç»„åˆå»ºè®®
            portfolio_advice = self.investment_advisor.generate_portfolio_advice(assets_advice)

            if format_type == 'markdown':
                lines.append(self._format_markdown_advice(assets_advice, portfolio_advice))
            else:
                lines.append(self._format_text_advice(assets_advice, portfolio_advice))

        except Exception as e:
            logger.error(f"ç”ŸæˆæŠ•èµ„å»ºè®®å¤±è´¥: {e}")
            if format_type == 'markdown':
                lines.append("âš ï¸ æŠ•èµ„å»ºè®®ç”Ÿæˆå¤±è´¥ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†åˆ†æç»“æœ")
            else:
                lines.append("æŠ•èµ„å»ºè®®ç”Ÿæˆå¤±è´¥")

        return '\n'.join(lines)

    def _extract_technical_data(self, data: dict) -> dict:
        """æå–æŠ€æœ¯åˆ†ææ•°æ®"""
        hist = data.get('historical_analysis', {})
        return {
            'current_price': hist.get('current_price', 0),
            'change_pct': hist.get('current_change_pct', 0)
        }

    def _extract_position_data(self, data: dict) -> dict:
        """æå–ä½ç½®åˆ†ææ•°æ®"""
        judgment = data.get('comprehensive_judgment', {})
        position_map = {
            'é«˜ä¼°': '80-90%', 'åé«˜': '70-80%', 'åˆç†': '50-70%',
            'åä½': '30-50%', 'ä½ä¼°': '20-30%', 'æä½': '10-20%'
        }
        position = judgment.get('recommended_position', '50-70%')

        return {
            'position_level': position,
            'position_pct': 60,  # é»˜è®¤å€¼
            'ma20_position_pct': 50  # é»˜è®¤å€¼
        }

    def _extract_volume_data(self, data: dict) -> dict:
        """æå–æˆäº¤é‡æ•°æ®"""
        return {
            'volume_ratio_20d': 1.0  # é»˜è®¤å€¼
        }

    def _format_markdown_advice(self, assets_advice: list, portfolio_advice: dict) -> str:
        """æ ¼å¼åŒ–MarkdownæŠ•èµ„å»ºè®® - ç®€åŒ–ç‰ˆï¼Œç›´æ¥æŒ‰æ–¹å‘åˆ¤æ–­å½’ç±»"""
        lines = []

        # ä»resultsä¸­æå–æ‰€æœ‰èµ„äº§çš„æ–¹å‘åˆ¤æ–­
        assets_by_direction = {
            'å¼ºçƒˆçœ‹å¤š': [],
            'çœ‹å¤š': [],
            'ä¸­æ€§åå¤š': [],
            'ä¸­æ€§': [],
            'çœ‹ç©º': []
        }

        # éå†æ‰€æœ‰èµ„äº§ï¼ŒæŒ‰æ–¹å‘åˆ†ç±»
        for advice in assets_advice:
            asset_name = advice['asset_name']
            # ä»asset_dataä¸­è·å–æ–¹å‘åˆ¤æ–­
            direction_raw = advice.get('direction', 'ä¸­æ€§')

            # å»æ‰emoji,åªä¿ç•™æ–‡å­—éƒ¨åˆ†
            direction = direction_raw.replace('âœ…âœ…', '').replace('âœ…', '').replace('âš–ï¸', '').replace('ğŸ”´', '').strip()

            if direction in assets_by_direction:
                assets_by_direction[direction].append(asset_name)

        # 1. å¼ºçƒˆçœ‹å¤š - å»ºè®®ç§¯æé…ç½®
        if assets_by_direction['å¼ºçƒˆçœ‹å¤š']:
            lines.append("### âœ…âœ… å¼ºçƒˆçœ‹å¤š (å»ºè®®ç§¯æé…ç½®)")
            lines.append("")
            lines.append("- " + "ã€".join(assets_by_direction['å¼ºçƒˆçœ‹å¤š']))
            lines.append("")

        # 2. çœ‹å¤š - å¯ä»¥é€‚åº¦é…ç½®
        if assets_by_direction['çœ‹å¤š']:
            lines.append("### âœ… çœ‹å¤š (å¯ä»¥é€‚åº¦é…ç½®)")
            lines.append("")
            lines.append("- " + "ã€".join(assets_by_direction['çœ‹å¤š']))
            lines.append("")

        # 3. ä¸­æ€§åå¤š - è§‚æœ›æˆ–å°‘é‡é…ç½®
        if assets_by_direction['ä¸­æ€§åå¤š']:
            lines.append("### âš–ï¸ ä¸­æ€§åå¤š (è§‚æœ›æˆ–å°‘é‡é…ç½®)")
            lines.append("")
            lines.append("- " + "ã€".join(assets_by_direction['ä¸­æ€§åå¤š']))
            lines.append("")

        # 4. ä¸­æ€§ - è§‚æœ›ä¸ºä¸»
        if assets_by_direction['ä¸­æ€§']:
            lines.append("### âšª ä¸­æ€§ (è§‚æœ›ä¸ºä¸»)")
            lines.append("")
            lines.append("- " + "ã€".join(assets_by_direction['ä¸­æ€§']))
            lines.append("")

        # 5. çœ‹ç©º - æš‚ä¸å»ºè®®å‚ä¸
        if assets_by_direction['çœ‹ç©º']:
            lines.append("### ğŸ”´ çœ‹ç©º (æš‚ä¸å»ºè®®å‚ä¸)")
            lines.append("")
            lines.append("- " + "ã€".join(assets_by_direction['çœ‹ç©º']))
            lines.append("")

        return '\n'.join(lines)

    def _format_text_advice(self, assets_advice: list, portfolio_advice: dict) -> str:
        """æ ¼å¼åŒ–æ–‡æœ¬æŠ•èµ„å»ºè®®"""
        lines = []

        lines.append("æ ¹æ®äº¤æ˜“ç³»ç»Ÿåˆ†æï¼Œç­›é€‰å‡ºä»¥ä¸‹æŠ•èµ„å»ºè®®ï¼š")
        lines.append("")

        # å¼ºçƒˆæ¨è
        strong_recommendations = [a for a in assets_advice if a['score'] >= 80]
        if strong_recommendations:
            lines.append("å¼ºçƒˆæ¨èå‚ä¸:")
            for advice in strong_recommendations:
                lines.append(f"  - {advice['asset_name']}: {advice['action']} ({advice['score']:.1f}åˆ†)")
            lines.append("")

        # è°¨æ…æ¨è
        moderate_recommendations = [a for a in assets_advice if 65 <= a['score'] < 80]
        if moderate_recommendations:
            lines.append("å¯è°¨æ…å‚ä¸:")
            for advice in moderate_recommendations:
                lines.append(f"  - {advice['asset_name']}: {advice['position_suggestion']} ({advice['score']:.1f}åˆ†)")
            lines.append("")

        # é£é™©æç¤º
        lines.append(f"é£é™©æç¤º: {portfolio_advice.get('risk_warning', 'æŠ•èµ„æœ‰é£é™©ï¼Œéœ€è°¨æ…')}")

        return '\n'.join(lines)

    def _format_sector_markdown(self, asset_key: str, data: dict, config: dict) -> str:
        """æ ¼å¼åŒ–å•ä¸ªæ¿å—ä¸º Markdown (å‚è€ƒ SectorReporter çš„æ ¼å¼)"""
        lines = []

        # æ ‡é¢˜
        lines.append(f"## {config['category'].upper()}: {data.get('sector_name', config['name'])}")
        lines.append("")
        lines.append(f"**æè¿°**: {config.get('description', 'N/A')}")
        lines.append("")

        # 1. å½“å‰ç‚¹ä½
        hist = data.get('historical_analysis', {})
        if hist and 'current_price' in hist:
            lines.append("### å½“å‰ç‚¹ä½")
            lines.append(f"- **æœ€æ–°ä»·æ ¼**: {hist['current_price']:.2f}")

            change_pct = hist.get('current_change_pct', 0)
            # ä¸­å›½è‚¡å¸‚ä¹ æƒ¯: çº¢æ¶¨ç»¿è·Œ
            change_emoji = "ğŸ”´" if change_pct >= 0 else "ğŸŸ¢"
            lines.append(f"- **æ¶¨è·Œå¹…**: {change_pct:+.2f}% {change_emoji}")
            lines.append(f"- **æ•°æ®æ—¥æœŸ**: {hist.get('current_date', 'N/A')}")
            lines.append("")

        # 2. ç»¼åˆåˆ¤æ–­
        judgment = data.get('comprehensive_judgment', {})
        if judgment:
            lines.append("### ç»¼åˆåˆ¤æ–­")

            direction = judgment.get('direction', 'N/A')
            direction_emoji_map = {
                'å¼ºçƒˆçœ‹å¤š': 'âœ…âœ…',
                'çœ‹å¤š': 'âœ…',
                'ä¸­æ€§åå¤š': 'âš–ï¸',
                'ä¸­æ€§': 'âš–ï¸',
                'çœ‹ç©º': 'ğŸ”´'
            }
            direction_emoji = direction_emoji_map.get(direction, 'âš–ï¸')
            lines.append(f"- **æ–¹å‘åˆ¤æ–­**: {direction}{direction_emoji}")
            lines.append(f"- **å»ºè®®ä»“ä½**: {judgment.get('recommended_position', 'N/A')}")
            lines.append("")

            strategies = judgment.get('strategies', [])
            if strategies:
                lines.append("**æ“ä½œç­–ç•¥**:")
                for strategy in strategies:
                    lines.append(f"  - {strategy}")
                lines.append("")

        # 3. å†å²ç‚¹ä½åˆ†æ
        if hist and '20d' in hist:
            lines.append("### å†å²ç‚¹ä½åˆ†æ")
            lines.append(f"- **ç›¸ä¼¼ç‚¹ä½**: {hist.get('similar_periods_count', 0)} ä¸ª")
            lines.append("")
            lines.append("| å‘¨æœŸ | ä¸Šæ¶¨æ¦‚ç‡ | å¹³å‡æ”¶ç›Š | æ”¶ç›Šä¸­ä½ | ç½®ä¿¡åº¦ |")
            lines.append("|------|----------|----------|----------|--------|")

            stats_20d = hist.get('20d', {})
            if stats_20d:
                lines.append(
                    f"| æœªæ¥20æ—¥ | {stats_20d.get('up_prob', 0):.1%} | "
                    f"{stats_20d.get('mean_return', 0):+.2%} | "
                    f"{stats_20d.get('median_return', 0):+.2%} | "
                    f"{stats_20d.get('confidence', 0):.1%} |"
                )

            stats_60d = hist.get('60d', {})
            if stats_60d and stats_60d.get('confidence', 0) > 0:
                lines.append(
                    f"| æœªæ¥60æ—¥ | {stats_60d.get('up_prob', 0):.1%} | "
                    f"{stats_60d.get('mean_return', 0):+.2%} | - | - |"
                )

            lines.append("")

        # 4. æŠ€æœ¯é¢åˆ†æ
        tech = data.get('technical_analysis', {})
        if tech and 'error' not in tech:
            lines.append("### æŠ€æœ¯é¢åˆ†æ")

            # MACD
            if 'macd' in tech:
                macd_status = 'âœ… é‡‘å‰' if tech['macd']['status'] == 'golden_cross' else 'ğŸ”´ æ­»å‰'
                lines.append(f"- **MACD**: {macd_status}")

            # RSI
            if 'rsi' in tech:
                rsi_val = tech['rsi']['value']
                rsi_status_map = {
                    'overbought': 'âš ï¸ è¶…ä¹°',
                    'oversold': 'âœ… è¶…å–',
                    'normal': 'ğŸ˜Š æ­£å¸¸'
                }
                rsi_status = rsi_status_map.get(tech['rsi']['status'], '')
                lines.append(f"- **RSI**: {rsi_val:.1f} ({rsi_status})")

            # KDJ
            if 'kdj' in tech:
                kdj = tech['kdj']
                kdj_signal = 'âœ…' if kdj['signal'] == 'golden_cross' else 'ğŸ”´'
                lines.append(f"- **KDJ**: K={kdj['k']:.1f}, D={kdj['d']:.1f}, J={kdj['j']:.1f} {kdj_signal}")

            # å¸ƒæ—å¸¦
            if 'boll' in tech:
                boll = tech['boll']
                boll_pos_pct = boll['position'] * 100
                boll_status_map = {
                    'near_upper': 'âš ï¸ æ¥è¿‘ä¸Šè½¨',
                    'near_lower': 'âœ… æ¥è¿‘ä¸‹è½¨',
                    'normal': 'ğŸ˜Š ä¸­è½¨åŒºåŸŸ'
                }
                boll_status = boll_status_map.get(boll['status'], '')
                lines.append(f"- **å¸ƒæ—å¸¦**: {boll_pos_pct:.0f}% ({boll_status})")

            # DMI/ADX
            if 'dmi_adx' in tech:
                dmi = tech['dmi_adx']
                trend_map = {'strong': 'strong ğŸ”¥', 'medium': 'medium ğŸ“Š', 'weak': 'weak âš¡'}
                direction_emoji = 'ğŸ“ˆ' if dmi['direction'] == 'bullish' else 'ğŸ“‰'
                lines.append(
                    f"- **DMI/ADX**: {dmi['adx']:.1f} ({trend_map.get(dmi['trend'], '')}, {direction_emoji})"
                )

            lines.append("")

        # 5. èµ„é‡‘é¢åˆ†æ
        capital = data.get('capital_flow', {})
        if capital and 'error' not in capital and capital.get('type'):
            lines.append("### èµ„é‡‘é¢åˆ†æ")
            flow_type = '**åŒ—å‘èµ„é‡‘(å¤–èµ„)**' if capital['type'] == 'northbound' else '**å—å‘èµ„é‡‘(å†…åœ°)**'
            lines.append(f"{flow_type}:")
            lines.append(f"- **è¿‘5æ—¥ç´¯è®¡**: {capital.get('recent_5d_flow', 0):.2f} äº¿å…ƒ")
            lines.append(f"- **æµå‘çŠ¶æ€**: {capital.get('status', 'N/A')}")
            lines.append(f"- **æƒ…ç»ªè¯„åˆ†**: {capital.get('sentiment_score', 50)}/100")
            lines.append("")

        # 6. é£é™©è¯„ä¼°
        risk = data.get('risk_assessment', {})
        if risk:
            lines.append("### é£é™©è¯„ä¼°")
            risk_level = risk.get('risk_level', 'N/A')
            risk_emoji_map = {
                'æé«˜é£é™©': 'ğŸ”´ğŸ”´ğŸ”´',
                'é«˜é£é™©': 'ğŸ”´ğŸ”´',
                'ä¸­é£é™©': 'âš ï¸',
                'ä½é£é™©': 'âœ…'
            }
            risk_emoji = risk_emoji_map.get(risk_level, '')
            lines.append(f"- **ç»¼åˆé£é™©**: {risk.get('risk_score', 0):.2f} ({risk_emoji} {risk_level})")

            risk_factors = risk.get('risk_factors', [])
            if risk_factors:
                lines.append("- **é£é™©å› ç´ **:")
                for factor in risk_factors:
                    lines.append(f"  - {factor}")

            lines.append("")

        # 7. æˆäº¤é‡åˆ†æ
        volume = data.get('volume_analysis', {})
        if volume and 'error' not in volume:
            lines.append("### æˆäº¤é‡åˆ†æ")
            obv = volume.get('obv_analysis', {})
            if obv:
                obv_trend = obv.get('trend', 'N/A')
                obv_emoji = 'â¡ï¸' if obv_trend in ['ä¸Šå‡', 'ä¸‹é™', 'å¹³ç¨³'] else ''
                lines.append(f"- **OBVè¶‹åŠ¿**: {obv_trend} {obv_emoji}")
            lines.append("")

        # 8. æ”¯æ’‘å‹åŠ›ä½
        sr = data.get('support_resistance', {})
        if sr and 'error' not in sr and sr.get('available', True):
            lines.append("### æ”¯æ’‘å‹åŠ›ä½")
            pivot = sr.get('pivot_points', {})
            if pivot:
                lines.append(f"- **è½´å¿ƒç‚¹**: {pivot.get('pivot', 0):.2f}")
                lines.append(f"- **é˜»åŠ›ä½**: R1={pivot.get('r1', 0):.2f}, R2={pivot.get('r2', 0):.2f}")
                lines.append(f"- **æ”¯æ’‘ä½**: S1={pivot.get('s1', 0):.2f}, S2={pivot.get('s2', 0):.2f}")
            lines.append("")

        lines.append("---")
        lines.append("")

        return '\n'.join(lines)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='ç»Ÿä¸€èµ„äº§åˆ†æå·¥å…· (æ•´åˆæŒ‡æ•°ã€æ¿å—ã€ä¸ªè‚¡åˆ†æ)'
    )
    parser.add_argument(
        '--assets',
        nargs='+',
        help='æŒ‡å®šèµ„äº§ä»£ç (å¦‚ CYBZ HK_BIOTECH SANHUA_A)ï¼Œä¸æŒ‡å®šåˆ™åˆ†ææ‰€æœ‰èµ„äº§'
    )
    parser.add_argument(
        '--save',
        type=str,
        help='ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶'
    )
    parser.add_argument(
        '--format',
        type=str,
        choices=['text', 'markdown'],
        default='markdown',
        help='æŠ¥å‘Šæ ¼å¼ (text æˆ– markdown)'
    )
    parser.add_argument(
        '--list',
        action='store_true',
        help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨èµ„äº§'
    )
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—'
    )
    parser.add_argument(
        '--email',
        action='store_true',
        help='å‘é€é‚®ä»¶åˆ°é…ç½®çš„æ”¶ä»¶äººåˆ—è¡¨'
    )

    args = parser.parse_args()

    # é…ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # åˆ—å‡ºæ‰€æœ‰èµ„äº§
    if args.list:
        print("=" * 80)
        print("æ‰€æœ‰å¯ç”¨èµ„äº§:")
        print("=" * 80)
        print(f"{'ä»£ç ':<20} {'åç§°':<20} {'ç±»åˆ«':<15} {'åˆ†æå™¨':<15}")
        print("-" * 80)

        for key, name, category, analyzer_type in list_all_assets():
            print(f"{key:<20} {name:<20} {category:<15} {analyzer_type:<15}")

        print("=" * 80)
        print(f"æ€»è®¡: {len(UNIFIED_ASSETS)} ä¸ªèµ„äº§")
        print("=" * 80)
        return

    try:
        print("=" * 80)
        print("ç»Ÿä¸€èµ„äº§åˆ†æå·¥å…·")
        print("=" * 80)

        # ç¡®å®šè¦åˆ†æçš„èµ„äº§
        asset_keys = args.assets
        if asset_keys:
            print(f"åˆ†æèµ„äº§: {', '.join(asset_keys)}")
        else:
            all_assets = list(UNIFIED_ASSETS.keys())
            asset_keys = all_assets
            print(f"åˆ†ææ‰€æœ‰èµ„äº§ ({len(asset_keys)} ä¸ª)")

        print("=" * 80)

        # æ‰§è¡Œåˆ†æ
        runner = UnifiedAnalysisRunner()
        results = runner.analyze_assets(asset_keys)

        # è¯»å–æŒä»“æ•°æ® (ä¼˜å…ˆçº§: ç¯å¢ƒå˜é‡ > æœ¬åœ°æœ€æ–°æ–‡ä»¶ > ç¤ºä¾‹æ–‡ä»¶)
        positions = None
        positions_dir = Path(__file__).parent.parent.parent / 'data'

        # ä¼˜å…ˆè¯»å–ç¯å¢ƒå˜é‡ POSITIONS_DATA (ç”¨äºGitHub workflow)
        import os
        import glob

        env_positions = os.getenv('POSITIONS_DATA')
        if env_positions:
            try:
                positions_raw = json.loads(env_positions)
                logger.info("âœ… ä»ç¯å¢ƒå˜é‡ POSITIONS_DATA è¯»å–æŒä»“æ•°æ®")

                # è½¬æ¢å­—æ®µå: position_ratio -> position_pct
                positions = []
                for p in positions_raw:
                    position_data = {
                        'asset_name': p.get('asset_name'),
                        'asset_code': p.get('asset_code'),
                        'asset_key': p.get('asset_key'),
                        'position_pct': p.get('position_ratio', 0),  # è½¬æ¢å­—æ®µå
                        'current_value': p.get('current_value', 0)
                    }
                    positions.append(position_data)

                logger.info(f"æˆåŠŸè¯»å– {len(positions)} ä¸ªæŒä»“ (æ¥æº: ç¯å¢ƒå˜é‡)")
            except Exception as e:
                logger.warning(f"è§£æç¯å¢ƒå˜é‡ POSITIONS_DATA å¤±è´¥: {e}, é™çº§åˆ°æœ¬åœ°æ–‡ä»¶")

        # å¦‚æœç¯å¢ƒå˜é‡æœªé…ç½®,è¯»å–æœ¬åœ°æ–‡ä»¶
        if positions is None:
            # ğŸ”§ ä¿®å¤: æŒ‰ä¿®æ”¹æ—¶é—´æ’åºè€Œéå­—å…¸åº
            position_files = sorted(
                glob.glob(str(positions_dir / 'positions_*.json')),
                key=os.path.getmtime,  # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
                reverse=True  # æœ€æ–°çš„åœ¨å‰
            )

            if position_files:
                # ä½¿ç”¨æœ€æ–°çš„æŒä»“æ–‡ä»¶
                latest_position_file = position_files[0]
                try:
                    with open(latest_position_file, 'r', encoding='utf-8') as f:
                        positions_raw = json.load(f)

                    # è½¬æ¢å­—æ®µå: position_ratio -> position_pct
                    positions = []
                    for p in positions_raw:
                        position_data = {
                            'asset_name': p.get('asset_name'),
                            'asset_code': p.get('asset_code'),
                            'asset_key': p.get('asset_key'),
                            'position_pct': p.get('position_ratio', 0),  # è½¬æ¢å­—æ®µå
                            'current_value': p.get('current_value', 0)
                        }
                        positions.append(position_data)

                    logger.info(f"æˆåŠŸè¯»å– {len(positions)} ä¸ªæŒä»“ (æ¥æº: {Path(latest_position_file).name})")
                except Exception as e:
                    logger.warning(f"è¯»å–æŒä»“æ•°æ®å¤±è´¥: {e}")

        # æ ¼å¼åŒ–æŠ¥å‘Š (ä¼ å…¥æŒä»“æ•°æ®)
        if positions:
            logger.info(f"âœ… å°†ä½¿ç”¨æŒä»“æ•°æ®ç”ŸæˆæŠ¥å‘Š, å…± {len(positions)} ä¸ªæŒä»“")
        else:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°æŒä»“æ•°æ®,å°†ç”Ÿæˆä¸åŒ…å«æŒä»“åˆ†æçš„æŠ¥å‘Š")

        report = runner.format_report(results, args.format, positions=positions)

        # æ‰“å°åˆ°æ§åˆ¶å° (å¤„ç† Windows GBK ç¼–ç )
        try:
            print("\n" + report)
        except UnicodeEncodeError:
            # Windows æ§åˆ¶å° GBK ç¼–ç ä¸æ”¯æŒ emoji å’Œç‰¹æ®Šå­—ç¬¦
            text_safe = report.encode('gbk', errors='ignore').decode('gbk')
            print("\n" + text_safe)

        # ä¿å­˜åˆ°æ–‡ä»¶
        if args.save:
            save_path = Path(args.save)
        else:
            # é»˜è®¤ä¿å­˜è·¯å¾„: russ_trading/reports/daily/YYYY-MM/å¸‚åœºæ´å¯ŸæŠ¥å‘Š_YYYYMMDD.md
            today = datetime.now()
            report_dir = Path(__file__).parent.parent / 'reports' / 'daily' / today.strftime('%Y-%m')
            save_path = report_dir / f"å¸‚åœºæ´å¯ŸæŠ¥å‘Š_{today.strftime('%Y%m%d')}.md"

        save_path.parent.mkdir(parents=True, exist_ok=True)
        with open(save_path, 'w', encoding='utf-8') as f:
            f.write(report)
        logger.info(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {save_path}")

        # å‘é€é‚®ä»¶(ä½¿ç”¨Markdownæ ¼å¼,è½¬HTML)
        if args.email:
            logger.info("å‡†å¤‡å‘é€é‚®ä»¶åˆ°é…ç½®çš„æ”¶ä»¶äººåˆ—è¡¨...")
            try:
                # é‚®ä»¶å‘é€ä½¿ç”¨Markdownæ ¼å¼æŠ¥å‘Š(å¿…é¡»ä¼ é€’positionså’Œmarket_dataä»¥ç”ŸæˆæŒä»“åˆ†æ)
                markdown_report = runner.format_report(results, 'markdown', positions=positions, market_data=results.get('market_state'))
                notifier = UnifiedEmailNotifier()
                success = notifier.send_unified_report(results, markdown_report)
                if success:
                    logger.info("âœ… é‚®ä»¶å‘é€æˆåŠŸ")
                else:
                    logger.error("âŒ é‚®ä»¶å‘é€å¤±è´¥")
                    sys.exit(1)
            except Exception as e:
                logger.error(f"é‚®ä»¶å‘é€å¼‚å¸¸: {str(e)}")
                logger.info("ğŸ’¡ æç¤º: è¯·ç¡®ä¿å·²é…ç½® config/email_config.yaml")
                sys.exit(1)

        logger.info("âœ… åˆ†æä»»åŠ¡å®Œæˆ")

    except Exception as e:
        logger.error(f"æ‰§è¡Œå¤±è´¥: {str(e)}", exc_info=True)
        sys.exit(1)


if __name__ == '__main__':
    main()
