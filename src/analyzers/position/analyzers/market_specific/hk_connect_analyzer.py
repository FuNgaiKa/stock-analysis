#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸¯è‚¡é€šæŒè‚¡æ•°æ®åˆ†æå™¨
HK Stock Connect Holdings Analyzer

åˆ†æåŒ—å‘èµ„é‡‘(æ¸¯è‚¡é€š)çš„æŒè‚¡å˜åŒ–:
- æŒè‚¡é‡‘é¢å˜åŒ–
- æŒè‚¡å æ¯”å˜åŒ–
- èµ„é‡‘æµå…¥æµå‡º
- å¸‚åœºæƒ…ç»ªåˆ¤æ–­

ä½œè€…: Claude Code
æ—¥æœŸ: 2025-10-12
"""

import akshare as ak
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import logging
from typing import Dict, Optional, List

logger = logging.getLogger(__name__)


class HKConnectAnalyzer:
    """
    æ¸¯è‚¡é€šæŒè‚¡åˆ†æå™¨

    åŠŸèƒ½:
    1. è·å–æ¸¯è‚¡é€š(å—å‘)èµ„é‡‘æµå‘æ•°æ®
    2. åˆ†æåŒ—å‘èµ„é‡‘æŒè‚¡å˜åŒ–
    3. è¯†åˆ«å¤–èµ„åå¥½è‚¡ç¥¨
    4. ç”Ÿæˆèµ„é‡‘æµå‘ä¿¡å·
    """

    def __init__(self, lookback_days: int = 60):
        """
        åˆå§‹åŒ–

        Args:
            lookback_days: å›æº¯å¤©æ•°,é»˜è®¤60å¤©
        """
        self.lookback_days = lookback_days
        logger.info("æ¸¯è‚¡é€šæŒè‚¡åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")

    def get_south_capital_flow(self, days: int = None) -> pd.DataFrame:
        """
        è·å–å—å‘èµ„é‡‘æµå‘æ•°æ®(æ¸¯è‚¡é€š)

        Args:
            days: è·å–æœ€è¿‘Nå¤©æ•°æ®

        Returns:
            DataFrame with columns: [æ—¥æœŸ, æ²ªæ¸¯é€š(äº¿), æ·±æ¸¯é€š(äº¿), å—å‘èµ„é‡‘(äº¿), ...]
        """
        try:
            logger.info("è·å–å—å‘èµ„é‡‘æµå‘æ•°æ®...")

            if days is None:
                days = self.lookback_days

            # ä½¿ç”¨akshareè·å–æ¸¯è‚¡é€šèµ„é‡‘æµå‘
            df = ak.stock_hsgt_fund_flow_summary_em()

            if df is None or df.empty:
                logger.warning("å—å‘èµ„é‡‘æ•°æ®ä¸ºç©º")
                return pd.DataFrame()

            # ç­›é€‰å—å‘æ•°æ®
            df_south = df[df['èµ„é‡‘æ–¹å‘'] == 'å—å‘'].copy()

            # è½¬æ¢æ—¥æœŸæ ¼å¼
            df_south['äº¤æ˜“æ—¥'] = pd.to_datetime(df_south['äº¤æ˜“æ—¥'])
            df_south = df_south.sort_values('äº¤æ˜“æ—¥', ascending=True)

            # ç­›é€‰æœ€è¿‘Nå¤©
            df_south = df_south.tail(days)

            logger.info(f"å—å‘èµ„é‡‘æ•°æ®è·å–æˆåŠŸ: {len(df_south)} æ¡è®°å½•")
            return df_south

        except Exception as e:
            logger.error(f"è·å–å—å‘èµ„é‡‘æ•°æ®å¤±è´¥: {str(e)}")
            return pd.DataFrame()

    def get_north_capital_flow(self, days: int = None) -> pd.DataFrame:
        """
        è·å–åŒ—å‘èµ„é‡‘æµå‘æ•°æ®(æ²ªæ·±è‚¡é€š)

        Args:
            days: è·å–æœ€è¿‘Nå¤©æ•°æ®

        Returns:
            DataFrame with columns: [æ—¥æœŸ, æ²ªè‚¡é€š(äº¿), æ·±è‚¡é€š(äº¿), åŒ—å‘èµ„é‡‘(äº¿), ...]
        """
        try:
            logger.info("è·å–åŒ—å‘èµ„é‡‘æµå‘æ•°æ®...")

            if days is None:
                days = self.lookback_days

            # è·å–æ²ªæ·±æ¸¯é€šèµ„é‡‘æµå‘
            df = ak.stock_hsgt_fund_flow_summary_em()

            if df is None or df.empty:
                logger.warning("åŒ—å‘èµ„é‡‘æ•°æ®ä¸ºç©º")
                return pd.DataFrame()

            # ç­›é€‰åŒ—å‘æ•°æ®
            df_north = df[df['èµ„é‡‘æ–¹å‘'] == 'åŒ—å‘'].copy()

            # è½¬æ¢æ—¥æœŸæ ¼å¼
            df_north['äº¤æ˜“æ—¥'] = pd.to_datetime(df_north['äº¤æ˜“æ—¥'])
            df_north = df_north.sort_values('äº¤æ˜“æ—¥', ascending=True)

            # ç­›é€‰æœ€è¿‘Nå¤©
            df_north = df_north.tail(days)

            logger.info(f"åŒ—å‘èµ„é‡‘æ•°æ®è·å–æˆåŠŸ: {len(df_north)} æ¡è®°å½•")
            return df_north

        except Exception as e:
            logger.error(f"è·å–åŒ—å‘èµ„é‡‘æ•°æ®å¤±è´¥: {str(e)}")
            return pd.DataFrame()

    def get_top_holdings(self, market: str = 'hk', top_n: int = 20) -> pd.DataFrame:
        """
        è·å–æ¸¯è‚¡é€š/æ²ªæ·±è‚¡é€šå‰Nå¤§æŒä»“è‚¡ç¥¨

        Args:
            market: 'hk'(æ¸¯è‚¡é€š) æˆ– 'sh'(æ²ªè‚¡é€š) æˆ– 'sz'(æ·±è‚¡é€š)
            top_n: è¿”å›å‰Nå

        Returns:
            DataFrame with columns: [æ’å, è‚¡ç¥¨ä»£ç , è‚¡ç¥¨åç§°, æŒè‚¡å¸‚å€¼, æŒè‚¡å æ¯”, ...]
        """
        try:
            logger.info(f"è·å–{market}å‰{top_n}å¤§æŒä»“è‚¡ç¥¨...")

            if market == 'hk':
                # è·å–æ¸¯è‚¡é€šåå¤§æˆäº¤è‚¡
                df = ak.stock_hsgt_stock_statistics_em(symbol='æ¸¯è‚¡é€š')
            elif market == 'sh':
                # è·å–æ²ªè‚¡é€šåå¤§æˆäº¤è‚¡
                df = ak.stock_hsgt_stock_statistics_em(symbol='æ²ªè‚¡é€š')
            elif market == 'sz':
                # è·å–æ·±è‚¡é€šåå¤§æˆäº¤è‚¡
                df = ak.stock_hsgt_stock_statistics_em(symbol='æ·±è‚¡é€š')
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„å¸‚åœº: {market}")

            if df is None or df.empty:
                logger.warning(f"{market}æŒä»“æ•°æ®ä¸ºç©º")
                return pd.DataFrame()

            # å–å‰Nå
            df = df.head(top_n)

            logger.info(f"{market}å‰{top_n}å¤§æŒä»“è·å–æˆåŠŸ")
            return df

        except Exception as e:
            logger.error(f"è·å–{market}æŒä»“æ•°æ®å¤±è´¥: {str(e)}")
            return pd.DataFrame()

    def calculate_flow_metrics(self, df: pd.DataFrame) -> Dict:
        """
        è®¡ç®—èµ„é‡‘æµå‘å…³é”®æŒ‡æ ‡

        Args:
            df: èµ„é‡‘æµå‘æ•°æ®DataFrame

        Returns:
            {
                'latest_date': æœ€æ–°æ—¥æœŸ,
                'latest_inflow': æœ€æ–°æµå…¥(äº¿),
                'total_inflow_5d': 5æ—¥ç´¯è®¡æµå…¥(äº¿),
                'total_inflow_20d': 20æ—¥ç´¯è®¡æµå…¥(äº¿),
                'avg_inflow_5d': 5æ—¥å¹³å‡æµå…¥(äº¿),
                'avg_inflow_20d': 20æ—¥å¹³å‡æµå…¥(äº¿),
                'inflow_trend': 'æŒç»­æµå…¥'/'æŒç»­æµå‡º'/'éœ‡è¡',
                'consecutive_days': è¿ç»­æµå…¥/æµå‡ºå¤©æ•°
            }
        """
        if df.empty or len(df) < 2:
            return {}

        try:
            # æœ€æ–°æ•°æ®
            latest = df.iloc[-1]
            latest_date = latest['äº¤æ˜“æ—¥']
            latest_inflow = float(latest.get('èµ„é‡‘å‡€æµå…¥', 0))

            # ç´¯è®¡æµå…¥
            total_inflow_5d = float(df.tail(5)['èµ„é‡‘å‡€æµå…¥'].sum()) if len(df) >= 5 else latest_inflow
            total_inflow_20d = float(df.tail(20)['èµ„é‡‘å‡€æµå…¥'].sum()) if len(df) >= 20 else total_inflow_5d

            # å¹³å‡æµå…¥
            avg_inflow_5d = total_inflow_5d / min(5, len(df))
            avg_inflow_20d = total_inflow_20d / min(20, len(df))

            # è¶‹åŠ¿åˆ¤æ–­
            consecutive_days = 0
            last_sign = np.sign(latest_inflow)

            for i in range(len(df) - 1, -1, -1):
                flow = df.iloc[i]['èµ„é‡‘å‡€æµå…¥']
                if np.sign(flow) == last_sign:
                    consecutive_days += 1
                else:
                    break

            if consecutive_days >= 3 and latest_inflow > 0:
                inflow_trend = 'æŒç»­æµå…¥'
            elif consecutive_days >= 3 and latest_inflow < 0:
                inflow_trend = 'æŒç»­æµå‡º'
            else:
                inflow_trend = 'éœ‡è¡'

            metrics = {
                'latest_date': latest_date.strftime('%Y-%m-%d'),
                'latest_inflow': latest_inflow,
                'total_inflow_5d': total_inflow_5d,
                'total_inflow_20d': total_inflow_20d,
                'avg_inflow_5d': avg_inflow_5d,
                'avg_inflow_20d': avg_inflow_20d,
                'inflow_trend': inflow_trend,
                'consecutive_days': consecutive_days
            }

            return metrics

        except Exception as e:
            logger.error(f"è®¡ç®—èµ„é‡‘æµå‘æŒ‡æ ‡å¤±è´¥: {str(e)}")
            return {}

    def analyze_capital_sentiment(self, metrics: Dict) -> Dict:
        """
        æ ¹æ®èµ„é‡‘æµå‘åˆ†æå¸‚åœºæƒ…ç»ª

        Args:
            metrics: èµ„é‡‘æµå‘æŒ‡æ ‡å­—å…¸

        Returns:
            {
                'sentiment': 'æåº¦ä¹è§‚'/'ä¹è§‚'/'ä¸­æ€§'/'æ‚²è§‚'/'æåº¦æ‚²è§‚',
                'sentiment_score': 0-100åˆ†,
                'signal': 'å¼ºä¹°å…¥'/'ä¹°å…¥'/'ä¸­æ€§'/'å–å‡º'/'å¼ºå–å‡º',
                'reasoning': åˆ¤æ–­ç†ç”±åˆ—è¡¨
            }
        """
        if not metrics:
            return {
                'sentiment': 'æœªçŸ¥',
                'sentiment_score': 50,
                'signal': 'ä¸­æ€§',
                'reasoning': ['æ•°æ®ä¸è¶³']
            }

        reasoning = []
        score = 50  # åŸºç¡€åˆ†50åˆ†

        # 1. æœ€æ–°æµå‘
        latest_inflow = metrics.get('latest_inflow', 0)
        if latest_inflow > 50:
            score += 15
            reasoning.append(f'å•æ—¥å‡€æµå…¥{latest_inflow:.1f}äº¿,å¤–èµ„å¤§å¹…ä¹°å…¥')
        elif latest_inflow > 20:
            score += 10
            reasoning.append(f'å•æ—¥å‡€æµå…¥{latest_inflow:.1f}äº¿,å¤–èµ„ç§¯æä¹°å…¥')
        elif latest_inflow < -50:
            score -= 15
            reasoning.append(f'å•æ—¥å‡€æµå‡º{abs(latest_inflow):.1f}äº¿,å¤–èµ„å¤§å¹…å–å‡º')
        elif latest_inflow < -20:
            score -= 10
            reasoning.append(f'å•æ—¥å‡€æµå‡º{abs(latest_inflow):.1f}äº¿,å¤–èµ„å–å‡º')

        # 2. 5æ—¥ç´¯è®¡
        total_5d = metrics.get('total_inflow_5d', 0)
        if total_5d > 100:
            score += 15
            reasoning.append(f'5æ—¥ç´¯è®¡æµå…¥{total_5d:.1f}äº¿,æŒç»­ä¹°å…¥')
        elif total_5d > 30:
            score += 8
            reasoning.append(f'5æ—¥ç´¯è®¡æµå…¥{total_5d:.1f}äº¿,ç¨³å®šæµå…¥')
        elif total_5d < -100:
            score -= 15
            reasoning.append(f'5æ—¥ç´¯è®¡æµå‡º{abs(total_5d):.1f}äº¿,æŒç»­å–å‡º')
        elif total_5d < -30:
            score -= 8
            reasoning.append(f'5æ—¥ç´¯è®¡æµå‡º{abs(total_5d):.1f}äº¿,ç¨³å®šæµå‡º')

        # 3. è¶‹åŠ¿åˆ¤æ–­
        trend = metrics.get('inflow_trend', 'éœ‡è¡')
        consecutive_days = metrics.get('consecutive_days', 0)

        if trend == 'æŒç»­æµå…¥':
            score += 10
            reasoning.append(f'è¿ç»­{consecutive_days}æ—¥å‡€æµå…¥,å¤–èµ„çœ‹å¤š')
        elif trend == 'æŒç»­æµå‡º':
            score -= 10
            reasoning.append(f'è¿ç»­{consecutive_days}æ—¥å‡€æµå‡º,å¤–èµ„çœ‹ç©º')
        else:
            reasoning.append('èµ„é‡‘æµå‘éœ‡è¡,å¤–èµ„è§‚æœ›')

        # é™åˆ¶åˆ†æ•°èŒƒå›´
        score = max(0, min(100, score))

        # æƒ…ç»ªåˆ¤æ–­
        if score >= 80:
            sentiment = 'æåº¦ä¹è§‚'
            signal = 'å¼ºä¹°å…¥'
        elif score >= 65:
            sentiment = 'ä¹è§‚'
            signal = 'ä¹°å…¥'
        elif score >= 45:
            sentiment = 'ä¸­æ€§'
            signal = 'ä¸­æ€§'
        elif score >= 30:
            sentiment = 'æ‚²è§‚'
            signal = 'å–å‡º'
        else:
            sentiment = 'æåº¦æ‚²è§‚'
            signal = 'å¼ºå–å‡º'

        return {
            'sentiment': sentiment,
            'sentiment_score': score,
            'signal': signal,
            'reasoning': reasoning
        }

    def comprehensive_analysis(self, direction: str = 'north') -> Dict:
        """
        ç»¼åˆåˆ†ææ¸¯è‚¡é€š/æ²ªæ·±è‚¡é€šèµ„é‡‘æµå‘

        Args:
            direction: 'north'(åŒ—å‘,æ²ªæ·±è‚¡é€š) æˆ– 'south'(å—å‘,æ¸¯è‚¡é€š)

        Returns:
            å®Œæ•´çš„åˆ†æç»“æœå­—å…¸
        """
        try:
            logger.info(f"å¼€å§‹æ¸¯è‚¡é€šèµ„é‡‘æµå‘ç»¼åˆåˆ†æ (æ–¹å‘: {direction})...")

            # è·å–æ•°æ®
            if direction == 'north':
                df = self.get_north_capital_flow()
                market_name = 'åŒ—å‘èµ„é‡‘(æ²ªæ·±è‚¡é€š)'
            elif direction == 'south':
                df = self.get_south_capital_flow()
                market_name = 'å—å‘èµ„é‡‘(æ¸¯è‚¡é€š)'
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–¹å‘: {direction}")

            if df.empty:
                return {
                    'error': 'è·å–æ•°æ®å¤±è´¥',
                    'timestamp': datetime.now()
                }

            # è®¡ç®—æŒ‡æ ‡
            metrics = self.calculate_flow_metrics(df)

            # åˆ†ææƒ…ç»ª
            sentiment_analysis = self.analyze_capital_sentiment(metrics)

            # å‡†å¤‡æ—¶é—´åºåˆ—æ•°æ® (æœ€è¿‘30å¤©)
            timeseries = []
            for idx, row in df.tail(30).iterrows():
                timeseries.append({
                    'date': row['äº¤æ˜“æ—¥'].strftime('%Y-%m-%d'),
                    'inflow': float(row.get('èµ„é‡‘å‡€æµå…¥', 0)),
                    'balance': float(row.get('å½“æ—¥èµ„é‡‘ä½™é¢', 0))
                })

            # è·å–å‰10å¤§æŒä»“(ä»…åŒ—å‘èµ„é‡‘)
            top_holdings = {}
            if direction == 'north':
                try:
                    sh_holdings = self.get_top_holdings(market='sh', top_n=10)
                    sz_holdings = self.get_top_holdings(market='sz', top_n=10)

                    if not sh_holdings.empty:
                        top_holdings['sh'] = sh_holdings.head(10).to_dict('records')
                    if not sz_holdings.empty:
                        top_holdings['sz'] = sz_holdings.head(10).to_dict('records')
                except Exception as e:
                    logger.warning(f"è·å–æŒä»“æ•°æ®å¤±è´¥: {str(e)}")

            result = {
                'market': market_name,
                'direction': direction,
                'metrics': metrics,
                'sentiment_analysis': sentiment_analysis,
                'timeseries': timeseries,
                'top_holdings': top_holdings,
                'timestamp': datetime.now()
            }

            logger.info("æ¸¯è‚¡é€šèµ„é‡‘æµå‘ç»¼åˆåˆ†æå®Œæˆ")
            return result

        except Exception as e:
            logger.error(f"æ¸¯è‚¡é€šç»¼åˆåˆ†æå¤±è´¥: {str(e)}")
            return {
                'error': str(e),
                'timestamp': datetime.now()
            }


if __name__ == '__main__':
    """æµ‹è¯•ä»£ç """
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    print("=" * 70)
    print("æ¸¯è‚¡é€šæŒè‚¡æ•°æ®åˆ†æå™¨æµ‹è¯•")
    print("=" * 70)

    analyzer = HKConnectAnalyzer(lookback_days=60)

    # æµ‹è¯•åŒ—å‘èµ„é‡‘åˆ†æ
    print("\n1. æµ‹è¯•åŒ—å‘èµ„é‡‘(æ²ªæ·±è‚¡é€š)åˆ†æ")
    print("-" * 70)
    result = analyzer.comprehensive_analysis(direction='north')

    if 'error' not in result:
        metrics = result['metrics']
        sentiment = result['sentiment_analysis']

        print(f"\nğŸ“Š èµ„é‡‘æµå‘æŒ‡æ ‡:")
        print(f"  æ—¥æœŸ: {metrics['latest_date']}")
        print(f"  æœ€æ–°æµå…¥: {metrics['latest_inflow']:.2f} äº¿å…ƒ")
        print(f"  5æ—¥ç´¯è®¡: {metrics['total_inflow_5d']:.2f} äº¿å…ƒ")
        print(f"  20æ—¥ç´¯è®¡: {metrics['total_inflow_20d']:.2f} äº¿å…ƒ")
        print(f"  5æ—¥å‡å€¼: {metrics['avg_inflow_5d']:.2f} äº¿å…ƒ/æ—¥")
        print(f"  è¶‹åŠ¿: {metrics['inflow_trend']}")
        print(f"  è¿ç»­å¤©æ•°: {metrics['consecutive_days']} å¤©")

        print(f"\nğŸ’¡ å¸‚åœºæƒ…ç»ªåˆ†æ:")
        print(f"  æƒ…ç»ª: {sentiment['sentiment']}")
        print(f"  è¯„åˆ†: {sentiment['sentiment_score']}/100")
        print(f"  ä¿¡å·: {sentiment['signal']}")
        print(f"  ç†ç”±:")
        for reason in sentiment['reasoning']:
            print(f"    - {reason}")

        print(f"\nğŸ“ˆ æ—¶é—´åºåˆ—: {len(result['timeseries'])} å¤©æ•°æ®")

        if result.get('top_holdings'):
            print(f"\nğŸ“‹ å‰10å¤§æŒä»“è‚¡ç¥¨:")
            if 'sh' in result['top_holdings']:
                print(f"  æ²ªè‚¡é€š: {len(result['top_holdings']['sh'])} åª")
            if 'sz' in result['top_holdings']:
                print(f"  æ·±è‚¡é€š: {len(result['top_holdings']['sz'])} åª")
    else:
        print(f"  âŒ åˆ†æå¤±è´¥: {result['error']}")

    # æµ‹è¯•å—å‘èµ„é‡‘åˆ†æ
    print("\n2. æµ‹è¯•å—å‘èµ„é‡‘(æ¸¯è‚¡é€š)åˆ†æ")
    print("-" * 70)
    result_south = analyzer.comprehensive_analysis(direction='south')

    if 'error' not in result_south:
        metrics_s = result_south['metrics']
        sentiment_s = result_south['sentiment_analysis']

        print(f"\nğŸ“Š å—å‘èµ„é‡‘æŒ‡æ ‡:")
        print(f"  æ—¥æœŸ: {metrics_s['latest_date']}")
        print(f"  æœ€æ–°æµå…¥: {metrics_s['latest_inflow']:.2f} äº¿å…ƒ")
        print(f"  5æ—¥ç´¯è®¡: {metrics_s['total_inflow_5d']:.2f} äº¿å…ƒ")
        print(f"  è¶‹åŠ¿: {metrics_s['inflow_trend']}")

        print(f"\nğŸ’¡ æƒ…ç»ª: {sentiment_s['sentiment']} ({sentiment_s['sentiment_score']}/100)")
        print(f"  ä¿¡å·: {sentiment_s['signal']}")
    else:
        print(f"  âŒ åˆ†æå¤±è´¥: {result_south['error']}")

    print("\n" + "=" * 70)
    print("âœ… æ¸¯è‚¡é€šæŒè‚¡æ•°æ®åˆ†æå™¨æµ‹è¯•å®Œæˆ")
    print("=" * 70)
