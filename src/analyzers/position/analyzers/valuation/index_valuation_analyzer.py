#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŒ‡æ•°ä¼°å€¼åˆ†æå™¨
Index Valuation Analyzer

åŠŸèƒ½:
1. PE/PBå†å²åˆ†ä½æ•°åˆ†æ
2. è‚¡å€ºæ”¶ç›Šæ¯”(ERP)è®¡ç®—
3. CAPEå¸­å‹’å¸‚ç›ˆç‡
4. ä¼°å€¼æ°´å¹³åˆ†ç±»

ä½œè€…: Claude Code
æ—¥æœŸ: 2025-10-16
"""

import akshare as ak
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import logging
from typing import Dict, Optional, List

logger = logging.getLogger(__name__)


class IndexValuationAnalyzer:
    """
    æŒ‡æ•°ä¼°å€¼åˆ†æå™¨

    æ”¯æŒAè‚¡ä¸»è¦æŒ‡æ•°çš„ä¼°å€¼åˆ†æ:
    - æ²ªæ·±300 (000300)
    - åˆ›ä¸šæ¿æŒ‡ (399006)
    - ç§‘åˆ›50 (000688)
    - ä¸­è¯500 (000905)
    - ä¸Šè¯æŒ‡æ•° (000001)
    """

    # æŒ‡æ•°ä»£ç æ˜ å°„
    INDEX_MAP = {
        '000300': 'æ²ªæ·±300',
        '399006': 'åˆ›ä¸šæ¿æŒ‡',
        '000688': 'ç§‘åˆ›50',
        '000905': 'ä¸­è¯500',
        '000001': 'ä¸Šè¯æŒ‡æ•°',
        '000050': 'ä¸Šè¯50',
        '000852': 'ä¸­è¯1000'
    }

    # ä»£ç åˆ°akshareåç§°çš„æ˜ å°„
    CODE_TO_AKSHARE_NAME = {
        '000300': 'æ²ªæ·±300',
        '399006': 'åˆ›ä¸šæ¿50',  # akshareä¸­æ˜¯åˆ›ä¸šæ¿50
        '000905': 'ä¸­è¯500',
        '000050': 'ä¸Šè¯50',
        '000852': 'ä¸­è¯1000'
    }

    def __init__(self, lookback_days: int = 1260):
        """
        åˆå§‹åŒ–ä¼°å€¼åˆ†æå™¨

        Args:
            lookback_days: å›æº¯å¤©æ•°,é»˜è®¤1260å¤©(çº¦5å¹´)
        """
        self.lookback_days = lookback_days
        self.cache = {}
        self.cache_time = {}
        self.cache_duration = 3600  # 1å°æ—¶ç¼“å­˜
        logger.info("æŒ‡æ•°ä¼°å€¼åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")

    def get_index_pe_pb_data(self, index_code: str) -> pd.DataFrame:
        """
        è·å–æŒ‡æ•°PE/PBå†å²æ•°æ®

        Args:
            index_code: æŒ‡æ•°ä»£ç  (å¦‚ '000300')

        Returns:
            DataFrame with columns: [date, pe, pb]
        """
        cache_key = f"pe_pb_{index_code}"

        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self.cache:
            if (datetime.now() - self.cache_time[cache_key]).seconds < self.cache_duration:
                logger.info(f"ä½¿ç”¨ç¼“å­˜çš„{index_code}ä¼°å€¼æ•°æ®")
                return self.cache[cache_key]

        try:
            # è½¬æ¢ä¸ºakshareæ¥å—çš„åç§°
            akshare_name = self.CODE_TO_AKSHARE_NAME.get(index_code)

            if not akshare_name:
                logger.warning(f"{index_code}ä¸åœ¨æ”¯æŒåˆ—è¡¨ä¸­")
                return pd.DataFrame()

            logger.info(f"è·å–{akshare_name}ä¼°å€¼æ•°æ®...")

            # è·å–PEæ•°æ®
            df_pe = ak.stock_index_pe_lg(symbol=akshare_name)

            if df_pe is None or df_pe.empty:
                logger.warning(f"{akshare_name} PEæ•°æ®ä¸ºç©º")
                return pd.DataFrame()

            # é‡å‘½åå¹¶é€‰æ‹©éœ€è¦çš„åˆ—
            df = df_pe[['æ—¥æœŸ', 'æ»šåŠ¨å¸‚ç›ˆç‡']].copy()
            df.rename(columns={'æ—¥æœŸ': 'date', 'æ»šåŠ¨å¸‚ç›ˆç‡': 'pe'}, inplace=True)

            # è½¬æ¢æ—¥æœŸæ ¼å¼
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values('date', ascending=True)

            # ç­›é€‰æœ€è¿‘Nå¤©
            df = df.tail(self.lookback_days)

            # å°è¯•è·å–PBæ•°æ®
            try:
                df_pb = ak.stock_index_pb_lg(symbol=akshare_name)
                if df_pb is not None and not df_pb.empty:
                    df_pb_sel = df_pb[['æ—¥æœŸ', 'æ»šåŠ¨å¸‚å‡€ç‡']].copy()
                    df_pb_sel.rename(columns={'æ—¥æœŸ': 'date', 'æ»šåŠ¨å¸‚å‡€ç‡': 'pb'}, inplace=True)
                    df_pb_sel['date'] = pd.to_datetime(df_pb_sel['date'])
                    df = pd.merge(df, df_pb_sel, on='date', how='left')
                    logger.info(f"è·å–{akshare_name} PBæ•°æ®æˆåŠŸ")
            except Exception as e:
                logger.warning(f"è·å–{akshare_name} PBæ•°æ®å¤±è´¥: {e}")
                df['pb'] = np.nan

            # ç¼“å­˜
            self.cache[cache_key] = df
            self.cache_time[cache_key] = datetime.now()

            logger.info(f"{akshare_name}ä¼°å€¼æ•°æ®è·å–æˆåŠŸ: {len(df)} æ¡è®°å½•")
            return df

        except Exception as e:
            logger.error(f"è·å–{index_code}ä¼°å€¼æ•°æ®å¤±è´¥: {str(e)}")
            return pd.DataFrame()


    def calculate_valuation_percentile(
        self,
        index_code: str,
        periods: List[int] = None
    ) -> Dict:
        """
        è®¡ç®—ä¼°å€¼å†å²åˆ†ä½æ•°

        Args:
            index_code: æŒ‡æ•°ä»£ç 
            periods: è¦è®¡ç®—çš„å‘¨æœŸåˆ—è¡¨(å¤©æ•°),é»˜è®¤[252, 756, 1260]

        Returns:
            åˆ†ä½æ•°åˆ†æå­—å…¸
        """
        if periods is None:
            periods = [252, 756, 1260]  # 1å¹´/3å¹´/5å¹´

        df = self.get_index_pe_pb_data(index_code)

        if df.empty or 'pe' not in df.columns:
            return {'error': f'{index_code}ä¼°å€¼æ•°æ®ä¸è¶³'}

        # è¿‡æ»¤æ— æ•ˆæ•°æ®
        df = df[df['pe'] > 0].copy()

        if len(df) < 30:
            return {'error': f'{index_code}æœ‰æ•ˆä¼°å€¼æ•°æ®ä¸è¶³30æ¡'}

        current_pe = df['pe'].iloc[-1]
        current_pb = df['pb'].iloc[-1] if 'pb' in df.columns and not pd.isna(df['pb'].iloc[-1]) else None

        result = {
            'index_code': index_code,
            'index_name': self.INDEX_MAP.get(index_code, index_code),
            'date': df['date'].iloc[-1].strftime('%Y-%m-%d') if 'date' in df.columns else datetime.now().strftime('%Y-%m-%d'),
            'current_pe': float(current_pe),
            'current_pb': float(current_pb) if current_pb else None,
            'pe_percentiles': {},
            'pb_percentiles': {}
        }

        # è®¡ç®—PEåˆ†ä½æ•°
        for period in periods:
            if len(df) >= period:
                hist_pe = df['pe'].tail(period)
                percentile = (hist_pe < current_pe).sum() / len(hist_pe) * 100

                label = f'{period // 252}å¹´' if period % 252 == 0 else f'{period}å¤©'

                result['pe_percentiles'][label] = {
                    'percentile': float(percentile),
                    'min': float(hist_pe.min()),
                    'max': float(hist_pe.max()),
                    'median': float(hist_pe.median()),
                    'mean': float(hist_pe.mean()),
                    'level': self._classify_percentile(percentile)
                }

        # è®¡ç®—PBåˆ†ä½æ•° (å¦‚æœæœ‰æ•°æ®)
        if current_pb and 'pb' in df.columns:
            df_pb = df[df['pb'] > 0].copy()
            for period in periods:
                if len(df_pb) >= period:
                    hist_pb = df_pb['pb'].tail(period)
                    percentile = (hist_pb < current_pb).sum() / len(hist_pb) * 100

                    label = f'{period // 252}å¹´' if period % 252 == 0 else f'{period}å¤©'

                    result['pb_percentiles'][label] = {
                        'percentile': float(percentile),
                        'min': float(hist_pb.min()),
                        'max': float(hist_pb.max()),
                        'median': float(hist_pb.median()),
                        'mean': float(hist_pb.mean()),
                        'level': self._classify_percentile(percentile)
                    }

        # ä¼°å€¼æ°´å¹³ç»¼åˆåˆ¤æ–­
        result['valuation_level'] = self._ç»¼åˆä¼°å€¼æ°´å¹³(result)

        return result

    def calculate_equity_risk_premium(self, index_code: str = '000300') -> Dict:
        """
        è®¡ç®—è‚¡å€ºæ”¶ç›Šæ¯” (Equity Risk Premium)

        ERP = è‚¡æ¯ç‡ - 10å¹´æœŸå›½å€ºæ”¶ç›Šç‡

        Args:
            index_code: æŒ‡æ•°ä»£ç ,é»˜è®¤æ²ªæ·±300

        Returns:
            ERPåˆ†æå­—å…¸
        """
        try:
            logger.info(f"è®¡ç®—{index_code}çš„è‚¡å€ºæ”¶ç›Šæ¯”...")

            # 1. è·å–10å¹´æœŸå›½å€ºæ”¶ç›Šç‡
            bond_yield_df = ak.bond_zh_us_rate()

            if bond_yield_df.empty:
                return {'error': 'æ— æ³•è·å–å›½å€ºæ”¶ç›Šç‡æ•°æ®'}

            # æœ€æ–°10å¹´æœŸå›½å€ºæ”¶ç›Šç‡
            latest_bond = bond_yield_df.iloc[-1]
            bond_yield_10y = float(latest_bond['ä¸­å›½å›½å€ºæ”¶ç›Šç‡10å¹´']) / 100  # è½¬æ¢ä¸ºå°æ•°

            # 2. è·å–æŒ‡æ•°è‚¡æ¯ç‡
            index_info = ak.index_stock_info()

            index_row = index_info[index_info['index_code'] == index_code]

            if index_row.empty:
                return {'error': f'æœªæ‰¾åˆ°{index_code}çš„è‚¡æ¯ç‡æ•°æ®'}

            # è‚¡æ¯ç‡ (éœ€è¦ç¡®è®¤akshareä¸­çš„å­—æ®µå)
            dividend_yield = None
            for col in ['dividend_yield', 'è‚¡æ¯ç‡', 'div_yield']:
                if col in index_row.columns:
                    dividend_yield = float(index_row.iloc[0][col])
                    if dividend_yield > 1:  # å¦‚æœæ˜¯ç™¾åˆ†æ¯”å½¢å¼
                        dividend_yield = dividend_yield / 100
                    break

            if dividend_yield is None or pd.isna(dividend_yield):
                logger.warning(f"{index_code}è‚¡æ¯ç‡æ•°æ®ä¸å¯ç”¨,ä½¿ç”¨é»˜è®¤å€¼2.5%")
                dividend_yield = 0.025  # é»˜è®¤2.5%

            # 3. è®¡ç®—ERP
            erp = dividend_yield - bond_yield_10y

            result = {
                'index_code': index_code,
                'index_name': self.INDEX_MAP.get(index_code, index_code),
                'dividend_yield': float(dividend_yield),
                'bond_yield_10y': float(bond_yield_10y),
                'equity_risk_premium': float(erp),
                'signal': self._interpret_erp(erp),
                'timestamp': datetime.now().strftime('%Y-%m-%d')
            }

            logger.info(f"ERPè®¡ç®—å®Œæˆ: {erp*100:.2f}%")
            return result

        except Exception as e:
            logger.error(f"è®¡ç®—ERPå¤±è´¥: {str(e)}")
            return {'error': str(e)}

    def comprehensive_analysis(self, index_codes: List[str] = None) -> Dict:
        """
        ç»¼åˆä¼°å€¼åˆ†æ

        Args:
            index_codes: è¦åˆ†æçš„æŒ‡æ•°ä»£ç åˆ—è¡¨,é»˜è®¤ä¸»è¦æŒ‡æ•°

        Returns:
            å®Œæ•´ä¼°å€¼åˆ†æç»“æœ
        """
        if index_codes is None:
            index_codes = ['000300', '000905', '000050']  # æ²ªæ·±300ã€ä¸­è¯500ã€ä¸Šè¯50

        logger.info(f"å¼€å§‹ç»¼åˆä¼°å€¼åˆ†æ: {len(index_codes)} ä¸ªæŒ‡æ•°")

        result = {
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'indices': {},
            'erp_analysis': {},
            'summary': {}
        }

        # åˆ†æå„æŒ‡æ•°ä¼°å€¼
        for code in index_codes:
            try:
                valuation = self.calculate_valuation_percentile(code)
                if 'error' not in valuation:
                    result['indices'][code] = valuation
            except Exception as e:
                logger.error(f"{code}ä¼°å€¼åˆ†æå¤±è´¥: {e}")

        # è‚¡å€ºæ”¶ç›Šæ¯”åˆ†æ (æ²ªæ·±300)
        if '000300' in index_codes:
            erp = self.calculate_equity_risk_premium('000300')
            if 'error' not in erp:
                result['erp_analysis'] = erp

        # ç”Ÿæˆæ‘˜è¦
        if result['indices']:
            result['summary'] = self._generate_summary(result)

        logger.info("ç»¼åˆä¼°å€¼åˆ†æå®Œæˆ")
        return result

    def _classify_percentile(self, percentile: float) -> str:
        """
        åˆ†ç±»ä¼°å€¼åˆ†ä½æ•°

        Args:
            percentile: åˆ†ä½æ•° (0-100)

        Returns:
            ä¼°å€¼æ°´å¹³æè¿°
        """
        if percentile < 20:
            return 'æä½ä¼°â¬‡ï¸â¬‡ï¸'
        elif percentile < 40:
            return 'ä½ä¼°â¬‡ï¸'
        elif percentile < 60:
            return 'åˆç†â¡ï¸'
        elif percentile < 80:
            return 'é«˜ä¼°â¬†ï¸'
        else:
            return 'æé«˜ä¼°â¬†ï¸â¬†ï¸'

    def _ç»¼åˆä¼°å€¼æ°´å¹³(self, valuation_data: Dict) -> Dict:
        """
        ç»¼åˆåˆ¤æ–­ä¼°å€¼æ°´å¹³

        Args:
            valuation_data: ä¼°å€¼æ•°æ®å­—å…¸

        Returns:
            ç»¼åˆä¼°å€¼æ°´å¹³åˆ¤æ–­
        """
        pe_percentiles = valuation_data.get('pe_percentiles', {})

        if not pe_percentiles:
            return {'level': 'æ•°æ®ä¸è¶³', 'emoji': 'â“'}

        # ä½¿ç”¨5å¹´åˆ†ä½æ•° (å¦‚æœæœ‰),å¦åˆ™ä½¿ç”¨æœ€é•¿å‘¨æœŸ
        if '5å¹´' in pe_percentiles:
            pe_pct = pe_percentiles['5å¹´']['percentile']
        else:
            # ä½¿ç”¨æœ€åä¸€ä¸ªå‘¨æœŸçš„åˆ†ä½æ•°
            pe_pct = list(pe_percentiles.values())[-1]['percentile']

        if pe_pct < 20:
            return {
                'level': 'æä½ä¼°',
                'emoji': 'â¬‡ï¸â¬‡ï¸',
                'signal': 'ä¹°å…¥æ—¶æœº',
                'description': f'PEå¤„äºå†å²{pe_pct:.0f}%åˆ†ä½,æä½ä¼°å€¼,å†å²ä¸Šå¾€å¾€æ˜¯å¥½çš„ä¹°å…¥æœºä¼š'
            }
        elif pe_pct < 40:
            return {
                'level': 'ä½ä¼°',
                'emoji': 'â¬‡ï¸',
                'signal': 'ç§¯æé…ç½®',
                'description': f'PEå¤„äºå†å²{pe_pct:.0f}%åˆ†ä½,ä¼°å€¼åä½,å¯ç§¯æé…ç½®'
            }
        elif pe_pct < 60:
            return {
                'level': 'åˆç†',
                'emoji': 'â¡ï¸',
                'signal': 'æ­£å¸¸æŒæœ‰',
                'description': f'PEå¤„äºå†å²{pe_pct:.0f}%åˆ†ä½,ä¼°å€¼åˆç†,å¯æ­£å¸¸æŒæœ‰'
            }
        elif pe_pct < 80:
            return {
                'level': 'é«˜ä¼°',
                'emoji': 'â¬†ï¸',
                'signal': 'æ³¨æ„é£é™©',
                'description': f'PEå¤„äºå†å²{pe_pct:.0f}%åˆ†ä½,ä¼°å€¼åé«˜,æ³¨æ„é£é™©'
            }
        else:
            return {
                'level': 'æé«˜ä¼°',
                'emoji': 'â¬†ï¸â¬†ï¸',
                'signal': 'è°¨æ…å‡ä»“',
                'description': f'PEå¤„äºå†å²{pe_pct:.0f}%åˆ†ä½,æé«˜ä¼°å€¼,å»ºè®®è°¨æ…å‡ä»“'
            }

    def _interpret_erp(self, erp: float) -> Dict:
        """
        è§£é‡Šè‚¡å€ºæ”¶ç›Šæ¯”

        Args:
            erp: è‚¡å€ºæ”¶ç›Šæ¯” (å°æ•°å½¢å¼)

        Returns:
            ERPè§£é‡Šå­—å…¸
        """
        erp_pct = erp * 100

        if erp > 0.015:  # >1.5%
            return {
                'level': 'è‚¡ç¥¨ç›¸å¯¹å¸å¼•',
                'emoji': 'âœ…',
                'description': f'ERP={erp_pct:+.2f}%,è‚¡ç¥¨ç›¸å¯¹å€ºåˆ¸æœ‰è¾ƒå¤§å¸å¼•åŠ›'
            }
        elif erp > 0:  # 0-1.5%
            return {
                'level': 'è‚¡ç¥¨ç•¥æœ‰å¸å¼•åŠ›',
                'emoji': 'ğŸŸ¢',
                'description': f'ERP={erp_pct:+.2f}%,è‚¡ç¥¨ç›¸å¯¹å€ºåˆ¸ç•¥æœ‰å¸å¼•åŠ›'
            }
        elif erp > -0.01:  # 0è‡³-1%
            return {
                'level': 'è‚¡å€ºå‡è¡¡',
                'emoji': 'ğŸŸ¡',
                'description': f'ERP={erp_pct:+.2f}%,è‚¡ç¥¨ä¸å€ºåˆ¸å¸å¼•åŠ›å‡è¡¡'
            }
        else:  # <-1%
            return {
                'level': 'å€ºåˆ¸æ›´æœ‰å¸å¼•åŠ›',
                'emoji': 'ğŸ”´',
                'description': f'ERP={erp_pct:+.2f}%,å€ºåˆ¸ç›¸å¯¹è‚¡ç¥¨æ›´æœ‰å¸å¼•åŠ›'
            }

    def _generate_summary(self, analysis_result: Dict) -> Dict:
        """
        ç”Ÿæˆåˆ†ææ‘˜è¦

        Args:
            analysis_result: å®Œæ•´åˆ†æç»“æœ

        Returns:
            æ‘˜è¦å­—å…¸
        """
        indices = analysis_result.get('indices', {})

        if not indices:
            return {'message': 'æ— ä¼°å€¼æ•°æ®'}

        # ç»Ÿè®¡å„ä¼°å€¼æ°´å¹³çš„æ•°é‡
        undervalued = []
        overvalued = []
        fair_valued = []

        for code, data in indices.items():
            level = data.get('valuation_level', {}).get('level', '')
            name = data.get('index_name', code)

            if 'ä½ä¼°' in level:
                undervalued.append(name)
            elif 'é«˜ä¼°' in level:
                overvalued.append(name)
            else:
                fair_valued.append(name)

        summary = {
            'undervalued_count': len(undervalued),
            'overvalued_count': len(overvalued),
            'fair_valued_count': len(fair_valued),
            'undervalued_indices': undervalued,
            'overvalued_indices': overvalued,
            'fair_valued_indices': fair_valued
        }

        # ç”Ÿæˆæ€»ä½“å»ºè®®
        if len(undervalued) >= len(indices) * 0.6:
            summary['overall_suggestion'] = "å¸‚åœºæ•´ä½“ä¼°å€¼åä½,å¯è€ƒè™‘å¢åŠ é…ç½®"
        elif len(overvalued) >= len(indices) * 0.6:
            summary['overall_suggestion'] = "å¸‚åœºæ•´ä½“ä¼°å€¼åé«˜,å»ºè®®æ§åˆ¶é£é™©"
        else:
            summary['overall_suggestion'] = "å¸‚åœºä¼°å€¼åˆ†åŒ–,ç²¾é€‰ä¸ªè‚¡/æŒ‡æ•°"

        return summary


def test_index_valuation_analyzer():
    """æµ‹è¯•æŒ‡æ•°ä¼°å€¼åˆ†æå™¨"""
    print("=" * 80)
    print("æŒ‡æ•°ä¼°å€¼åˆ†æå™¨æµ‹è¯•")
    print("=" * 80)

    analyzer = IndexValuationAnalyzer(lookback_days=1260)

    # æµ‹è¯•1: å•ä¸ªæŒ‡æ•°ä¼°å€¼åˆ†æ
    print("\n1. æµ‹è¯•æ²ªæ·±300ä¼°å€¼åˆ†æ")
    print("-" * 80)
    result = analyzer.calculate_valuation_percentile('000300')

    if 'error' not in result:
        print(f"\n{result['index_name']} ({result['index_code']})")
        print(f"æ—¥æœŸ: {result['date']}")
        print(f"å½“å‰PE: {result['current_pe']:.2f}")
        if result['current_pb']:
            print(f"å½“å‰PB: {result['current_pb']:.2f}")

        print(f"\nPEå†å²åˆ†ä½æ•°:")
        for period, data in result['pe_percentiles'].items():
            print(f"  {period}: {data['percentile']:.1f}% "
                  f"(å‡å€¼ {data['mean']:.2f}, ä¸­ä½æ•° {data['median']:.2f}) "
                  f"{data['level']}")

        val_level = result['valuation_level']
        print(f"\nä¼°å€¼æ°´å¹³: {val_level['emoji']} {val_level['level']}")
        print(f"ä¿¡å·: {val_level['signal']}")
        print(f"è¯´æ˜: {val_level['description']}")
    else:
        print(f"  âŒ åˆ†æå¤±è´¥: {result['error']}")

    # æµ‹è¯•2: è‚¡å€ºæ”¶ç›Šæ¯”
    print("\n\n2. æµ‹è¯•è‚¡å€ºæ”¶ç›Šæ¯”åˆ†æ")
    print("-" * 80)
    erp_result = analyzer.calculate_equity_risk_premium('000300')

    if 'error' not in erp_result:
        print(f"\n{erp_result['index_name']} è‚¡å€ºæ”¶ç›Šæ¯”:")
        print(f"  è‚¡æ¯ç‡: {erp_result['dividend_yield']*100:.2f}%")
        print(f"  10å¹´å›½å€ºæ”¶ç›Šç‡: {erp_result['bond_yield_10y']*100:.2f}%")
        print(f"  ERP: {erp_result['equity_risk_premium']*100:+.2f}%")
        print(f"\n  {erp_result['signal']['emoji']} {erp_result['signal']['level']}")
        print(f"  {erp_result['signal']['description']}")
    else:
        print(f"  âŒ åˆ†æå¤±è´¥: {erp_result['error']}")

    # æµ‹è¯•3: ç»¼åˆåˆ†æ
    print("\n\n3. æµ‹è¯•ç»¼åˆä¼°å€¼åˆ†æ")
    print("-" * 80)
    comp_result = analyzer.comprehensive_analysis(['000300', '000905', '000050'])

    if comp_result.get('summary') and comp_result['summary']:
        summary = comp_result['summary']
        print(f"\nä¼°å€¼æ‘˜è¦:")
        print(f"  ä½ä¼°æŒ‡æ•°: {summary.get('undervalued_count', 0)} ä¸ª")
        if summary.get('undervalued_indices'):
            print(f"    {', '.join(summary['undervalued_indices'])}")
        print(f"  åˆç†æŒ‡æ•°: {summary.get('fair_valued_count', 0)} ä¸ª")
        if summary.get('fair_valued_indices'):
            print(f"    {', '.join(summary['fair_valued_indices'])}")
        print(f"  é«˜ä¼°æŒ‡æ•°: {summary.get('overvalued_count', 0)} ä¸ª")
        if summary.get('overvalued_indices'):
            print(f"    {', '.join(summary['overvalued_indices'])}")
        print(f"\n  æ€»ä½“å»ºè®®: {summary.get('overall_suggestion', 'N/A')}")
    else:
        print("  âš ï¸ æ— ä¼°å€¼æ‘˜è¦æ•°æ®")

    print("\n" + "=" * 80)
    print("âœ… æŒ‡æ•°ä¼°å€¼åˆ†æå™¨æµ‹è¯•å®Œæˆ")
    print("=" * 80)


if __name__ == '__main__':
    """æµ‹è¯•ä»£ç """
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    test_index_valuation_analyzer()
